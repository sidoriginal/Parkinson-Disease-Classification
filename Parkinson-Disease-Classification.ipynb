{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "peNl08iQTcUT",
        "bTjZd4gTTxF_",
        "K-yylwZmVsTX",
        "04RzAzGAXja1",
        "gvtgQX7-ZSbO",
        "jTSJDE8RbE3v",
        "PGgA_Oq7dgkL",
        "LEC1K5KDdlmc",
        "GqHwNTT3dqrk",
        "XQLuRRNGdvEb",
        "u-Mc0S-pdzf1"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Importing Libraries and setting the seed"
      ],
      "metadata": {
        "id": "peNl08iQTcUT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f2CegkZ_G1Cd"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "%pip install xgboost\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv1D, Flatten, MaxPooling1D, Dropout, BatchNormalization, Activation,SimpleRNN, LSTM, GRU\n",
        "\n",
        "\n",
        "np.random.seed(42)\n",
        "random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "os.environ['PYTHONHASHSEED'] = str(42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **PD Speech Dataset: Signal Processing for Diagnosis**\n",
        "### **Data Set Information**:\n",
        "The data used in this study were gathered from 188 patients with PD (107 men and 81 women) with ages ranging from 33 to 87 (65.1Â±10.9) at the Department of Neurology in CerrahpaÅŸa Faculty of Medicine, Istanbul University. The control group consists of 64 healthy individuals (23 men and 41 women) with ages varying between 41 and 82 (61.1Â±8.9). During the data collection process, the microphone is set to 44.1 KHz and following the physicianâ€™s examination, the sustained phonation of the vowel /a/ was collected from each subject with three repetitions.\n",
        "### **Attribute Information**:\n",
        "Various speech signal processing algorithms including Time Frequency Features, Mel Frequency Cepstral Coefficients (MFCCs), Wavelet Transform based Features, Vocal Fold Features and TWQT features have been applied to the speech recordings of Parkinson's Disease (PD) patients to extract clinically useful information for PD assessment."
      ],
      "metadata": {
        "id": "fhikHG3mUnys"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reading file and doing train, validate and test splitting"
      ],
      "metadata": {
        "id": "bTjZd4gTTxF_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = 'pd_speech_features.csv'\n",
        "data = pd.read_csv(file_path)\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "ViJQYAoMhaCA",
        "outputId": "7bb8ae0b-9ea8-4f7c-c9de-d9730b2b8b3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id  gender      PPE      DFA     RPDE  numPulses  numPeriodsPulses  \\\n",
              "0   0       1  0.85247  0.71826  0.57227        240               239   \n",
              "1   0       1  0.76686  0.69481  0.53966        234               233   \n",
              "2   0       1  0.85083  0.67604  0.58982        232               231   \n",
              "3   1       0  0.41121  0.79672  0.59257        178               177   \n",
              "4   1       0  0.32790  0.79782  0.53028        236               235   \n",
              "\n",
              "   meanPeriodPulses  stdDevPeriodPulses  locPctJitter  ...  \\\n",
              "0          0.008064            0.000087       0.00218  ...   \n",
              "1          0.008258            0.000073       0.00195  ...   \n",
              "2          0.008340            0.000060       0.00176  ...   \n",
              "3          0.010858            0.000183       0.00419  ...   \n",
              "4          0.008162            0.002669       0.00535  ...   \n",
              "\n",
              "   tqwt_kurtosisValue_dec_28  tqwt_kurtosisValue_dec_29  \\\n",
              "0                     1.5620                     2.6445   \n",
              "1                     1.5589                     3.6107   \n",
              "2                     1.5643                     2.3308   \n",
              "3                     3.7805                     3.5664   \n",
              "4                     6.1727                     5.8416   \n",
              "\n",
              "   tqwt_kurtosisValue_dec_30  tqwt_kurtosisValue_dec_31  \\\n",
              "0                     3.8686                     4.2105   \n",
              "1                    23.5155                    14.1962   \n",
              "2                     9.4959                    10.7458   \n",
              "3                     5.2558                    14.0403   \n",
              "4                     6.0805                     5.7621   \n",
              "\n",
              "   tqwt_kurtosisValue_dec_32  tqwt_kurtosisValue_dec_33  \\\n",
              "0                     5.1221                     4.4625   \n",
              "1                    11.0261                     9.5082   \n",
              "2                    11.0177                     4.8066   \n",
              "3                     4.2235                     4.6857   \n",
              "4                     7.7817                    11.6891   \n",
              "\n",
              "   tqwt_kurtosisValue_dec_34  tqwt_kurtosisValue_dec_35  \\\n",
              "0                     2.6202                     3.0004   \n",
              "1                     6.5245                     6.3431   \n",
              "2                     2.9199                     3.1495   \n",
              "3                     4.8460                     6.2650   \n",
              "4                     8.2103                     5.0559   \n",
              "\n",
              "   tqwt_kurtosisValue_dec_36  class  \n",
              "0                    18.9405      1  \n",
              "1                    45.1780      1  \n",
              "2                     4.7666      1  \n",
              "3                     4.0603      1  \n",
              "4                     6.1164      1  \n",
              "\n",
              "[5 rows x 755 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ddcf928f-2674-447c-890f-4a47fa418665\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>gender</th>\n",
              "      <th>PPE</th>\n",
              "      <th>DFA</th>\n",
              "      <th>RPDE</th>\n",
              "      <th>numPulses</th>\n",
              "      <th>numPeriodsPulses</th>\n",
              "      <th>meanPeriodPulses</th>\n",
              "      <th>stdDevPeriodPulses</th>\n",
              "      <th>locPctJitter</th>\n",
              "      <th>...</th>\n",
              "      <th>tqwt_kurtosisValue_dec_28</th>\n",
              "      <th>tqwt_kurtosisValue_dec_29</th>\n",
              "      <th>tqwt_kurtosisValue_dec_30</th>\n",
              "      <th>tqwt_kurtosisValue_dec_31</th>\n",
              "      <th>tqwt_kurtosisValue_dec_32</th>\n",
              "      <th>tqwt_kurtosisValue_dec_33</th>\n",
              "      <th>tqwt_kurtosisValue_dec_34</th>\n",
              "      <th>tqwt_kurtosisValue_dec_35</th>\n",
              "      <th>tqwt_kurtosisValue_dec_36</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.85247</td>\n",
              "      <td>0.71826</td>\n",
              "      <td>0.57227</td>\n",
              "      <td>240</td>\n",
              "      <td>239</td>\n",
              "      <td>0.008064</td>\n",
              "      <td>0.000087</td>\n",
              "      <td>0.00218</td>\n",
              "      <td>...</td>\n",
              "      <td>1.5620</td>\n",
              "      <td>2.6445</td>\n",
              "      <td>3.8686</td>\n",
              "      <td>4.2105</td>\n",
              "      <td>5.1221</td>\n",
              "      <td>4.4625</td>\n",
              "      <td>2.6202</td>\n",
              "      <td>3.0004</td>\n",
              "      <td>18.9405</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.76686</td>\n",
              "      <td>0.69481</td>\n",
              "      <td>0.53966</td>\n",
              "      <td>234</td>\n",
              "      <td>233</td>\n",
              "      <td>0.008258</td>\n",
              "      <td>0.000073</td>\n",
              "      <td>0.00195</td>\n",
              "      <td>...</td>\n",
              "      <td>1.5589</td>\n",
              "      <td>3.6107</td>\n",
              "      <td>23.5155</td>\n",
              "      <td>14.1962</td>\n",
              "      <td>11.0261</td>\n",
              "      <td>9.5082</td>\n",
              "      <td>6.5245</td>\n",
              "      <td>6.3431</td>\n",
              "      <td>45.1780</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.85083</td>\n",
              "      <td>0.67604</td>\n",
              "      <td>0.58982</td>\n",
              "      <td>232</td>\n",
              "      <td>231</td>\n",
              "      <td>0.008340</td>\n",
              "      <td>0.000060</td>\n",
              "      <td>0.00176</td>\n",
              "      <td>...</td>\n",
              "      <td>1.5643</td>\n",
              "      <td>2.3308</td>\n",
              "      <td>9.4959</td>\n",
              "      <td>10.7458</td>\n",
              "      <td>11.0177</td>\n",
              "      <td>4.8066</td>\n",
              "      <td>2.9199</td>\n",
              "      <td>3.1495</td>\n",
              "      <td>4.7666</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.41121</td>\n",
              "      <td>0.79672</td>\n",
              "      <td>0.59257</td>\n",
              "      <td>178</td>\n",
              "      <td>177</td>\n",
              "      <td>0.010858</td>\n",
              "      <td>0.000183</td>\n",
              "      <td>0.00419</td>\n",
              "      <td>...</td>\n",
              "      <td>3.7805</td>\n",
              "      <td>3.5664</td>\n",
              "      <td>5.2558</td>\n",
              "      <td>14.0403</td>\n",
              "      <td>4.2235</td>\n",
              "      <td>4.6857</td>\n",
              "      <td>4.8460</td>\n",
              "      <td>6.2650</td>\n",
              "      <td>4.0603</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.32790</td>\n",
              "      <td>0.79782</td>\n",
              "      <td>0.53028</td>\n",
              "      <td>236</td>\n",
              "      <td>235</td>\n",
              "      <td>0.008162</td>\n",
              "      <td>0.002669</td>\n",
              "      <td>0.00535</td>\n",
              "      <td>...</td>\n",
              "      <td>6.1727</td>\n",
              "      <td>5.8416</td>\n",
              "      <td>6.0805</td>\n",
              "      <td>5.7621</td>\n",
              "      <td>7.7817</td>\n",
              "      <td>11.6891</td>\n",
              "      <td>8.2103</td>\n",
              "      <td>5.0559</td>\n",
              "      <td>6.1164</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 755 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ddcf928f-2674-447c-890f-4a47fa418665')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ddcf928f-2674-447c-890f-4a47fa418665 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ddcf928f-2674-447c-890f-4a47fa418665');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-3bfdd274-3923-4cd0-bc4b-f2a0322de69a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3bfdd274-3923-4cd0-bc4b-f2a0322de69a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-3bfdd274-3923-4cd0-bc4b-f2a0322de69a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VpDD6JtS3Dnx",
        "outputId": "112e24ea-38c8-47ec-a5e2-5199fd4c7c18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(756, 755)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.iloc[1:]\n",
        "\n",
        "# Ensuring that all data is numeric\n",
        "data = data.apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "# Handling missing values if any\n",
        "data = data.dropna()\n",
        "\n",
        "# Preprocessing the dataset\n",
        "X = data.iloc[:, 1:-1].values  # Excluding 'id' and 'class' columns\n",
        "y = data.iloc[:, -1].values   # 'class' column\n",
        "\n",
        "# Normalizing the features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Reshaping X for 1D CNN input\n",
        "X_reshaped = np.expand_dims(X_scaled, axis=2)\n",
        "\n",
        "# Splitting the dataset\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X_reshaped, y, test_size=0.4, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "epochs = 25  # Number of epochs;\n",
        "batch_size = 80  # Batch size;\n"
      ],
      "metadata": {
        "id": "o7nhWJVK3Egl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Definition of Convolutional Neural Networks (CNNs)**\n",
        "Convolutional Neural Networks (CNNs) are a class of deep neural networks, most commonly applied to analyzing visual imagery. They are particularly known for their ability to detect patterns and features in images through a process known as convolution, which involves sliding a filter or kernel over the input data to produce a feature map. This process captures local dependencies in the data, such as edges and textures in images. CNNs typically consist of a series of layers: convolutional layers for feature extraction, pooling layers for dimensionality reduction, and fully connected layers for classification or regression tasks.\n",
        "\n",
        "\n",
        "\n",
        "### **CNNs in the Context of PD Speech Data**\n",
        "When applied to datasets like PD (Parkinson's Disease) speech, CNNs can be adapted to process one-dimensional time-series data instead of two-dimensional image data. In this context, CNNs work by:\n",
        "\n",
        "* Feature Extraction: Extracting relevant features from the speech signals, which may include aspects like frequency changes, amplitude variations, and temporal dynamics. These features are crucial in identifying speech characteristics that may be indicative of Parkinson's Disease.\n",
        "\n",
        "* Capturing Temporal Patterns: Using 1D convolutional layers, CNNs can capture temporal patterns within the speech data. The convolution operation allows the network to recognize specific patterns in the speech signal that are consistently associated with PD symptoms.\n",
        "\n",
        "* Handling Varied Input Lengths: Speech data often comes in varied lengths. CNNs can manage this through techniques like padding or cutting to ensure consistent input sizes or by using global pooling layers to handle inputs of varying dimensions.\n",
        "\n",
        "* Classification: After feature extraction and pattern recognition, CNNs use one or more fully connected layers to classify the speech samples into categories (such as PD or non-PD) based on the learned features.\n",
        "\n",
        "In summary, CNNs, when used for PD speech datasets, focus on automatically learning speech signal features that are relevant for distinguishing between healthy individuals and those affected by Parkinson's Disease. This involves adapting the network to handle one-dimensional, time-series data, focusing on temporal feature extraction, and employing classification layers to make predictions based on these features."
      ],
      "metadata": {
        "id": "H3958pR7U0I8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating different types of CNNs and evaluating their results"
      ],
      "metadata": {
        "id": "K-yylwZmVsTX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_cnn_model_1(input_shape):\n",
        "    # Simple CNN model\n",
        "    model = Sequential([\n",
        "        Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=input_shape),\n",
        "        MaxPooling1D(pool_size=2),\n",
        "        Flatten(),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def create_cnn_model_2(input_shape):\n",
        "    # CNN model with more layers\n",
        "    model = Sequential([\n",
        "        Conv1D(filters=64, kernel_size=5, input_shape=input_shape),\n",
        "        BatchNormalization(),\n",
        "        Activation('relu'),\n",
        "        MaxPooling1D(pool_size=2),\n",
        "        Conv1D(filters=128, kernel_size=3),\n",
        "        BatchNormalization(),\n",
        "        Activation('relu'),\n",
        "        MaxPooling1D(pool_size=2),\n",
        "        Flatten(),\n",
        "        Dense(256, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def create_cnn_model_3(input_shape):\n",
        "    # CNN model with different kernel sizes\n",
        "    model = Sequential([\n",
        "        Conv1D(filters=32, kernel_size=3, input_shape=input_shape),\n",
        "        Activation('relu'),\n",
        "        Conv1D(filters=32, kernel_size=3),\n",
        "        Activation('relu'),\n",
        "        MaxPooling1D(pool_size=2),\n",
        "        Flatten(),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Function to train and evaluate a model\n",
        "def train_and_evaluate_model(model, X_train, y_train, X_test, y_test, epochs=10, batch_size=32):\n",
        "    model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_split=0.2)\n",
        "    test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "    return test_loss, test_accuracy\n",
        "\n",
        "# Creating models\n",
        "input_shape = (X_train.shape[1], 1)\n",
        "model_1 = create_cnn_model_1(input_shape)\n",
        "model_2 = create_cnn_model_2(input_shape)\n",
        "model_3 = create_cnn_model_3(input_shape)\n",
        "\n",
        "# Training and evaluating models\n",
        "loss_1, acc_1 = train_and_evaluate_model(model_1, X_train, y_train, X_test, y_test)\n",
        "loss_2, acc_2 = train_and_evaluate_model(model_2, X_train, y_train, X_test, y_test)\n",
        "loss_3, acc_3 = train_and_evaluate_model(model_3, X_train, y_train, X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qxuxDTrf6FFO",
        "outputId": "dde22a5d-57a4-4bb8-aaf7-dd68efe26a9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "12/12 [==============================] - 2s 65ms/step - loss: 0.8218 - accuracy: 0.6657 - val_loss: 0.3485 - val_accuracy: 0.8901\n",
            "Epoch 2/10\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 0.4685 - accuracy: 0.7845 - val_loss: 0.3585 - val_accuracy: 0.8462\n",
            "Epoch 3/10\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 0.3280 - accuracy: 0.8536 - val_loss: 0.3699 - val_accuracy: 0.8571\n",
            "Epoch 4/10\n",
            "12/12 [==============================] - 1s 48ms/step - loss: 0.3048 - accuracy: 0.8646 - val_loss: 0.3436 - val_accuracy: 0.8571\n",
            "Epoch 5/10\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 0.2672 - accuracy: 0.8867 - val_loss: 0.3297 - val_accuracy: 0.8681\n",
            "Epoch 6/10\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 0.2249 - accuracy: 0.9171 - val_loss: 0.3183 - val_accuracy: 0.8571\n",
            "Epoch 7/10\n",
            "12/12 [==============================] - 1s 48ms/step - loss: 0.1946 - accuracy: 0.9392 - val_loss: 0.3144 - val_accuracy: 0.8681\n",
            "Epoch 8/10\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 0.1803 - accuracy: 0.9227 - val_loss: 0.3169 - val_accuracy: 0.8681\n",
            "Epoch 9/10\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 0.1484 - accuracy: 0.9475 - val_loss: 0.3210 - val_accuracy: 0.8681\n",
            "Epoch 10/10\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 0.1225 - accuracy: 0.9586 - val_loss: 0.3080 - val_accuracy: 0.8791\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.3705 - accuracy: 0.8411\n",
            "Epoch 1/10\n",
            "12/12 [==============================] - 12s 457ms/step - loss: 4.5976 - accuracy: 0.7044 - val_loss: 0.7102 - val_accuracy: 0.5934\n",
            "Epoch 2/10\n",
            "12/12 [==============================] - 5s 402ms/step - loss: 2.4222 - accuracy: 0.7403 - val_loss: 0.4776 - val_accuracy: 0.7912\n",
            "Epoch 3/10\n",
            "12/12 [==============================] - 7s 635ms/step - loss: 1.5127 - accuracy: 0.7044 - val_loss: 0.3655 - val_accuracy: 0.8132\n",
            "Epoch 4/10\n",
            "12/12 [==============================] - 3s 274ms/step - loss: 0.5289 - accuracy: 0.8094 - val_loss: 0.5753 - val_accuracy: 0.8132\n",
            "Epoch 5/10\n",
            "12/12 [==============================] - 2s 198ms/step - loss: 0.3905 - accuracy: 0.8453 - val_loss: 0.4027 - val_accuracy: 0.7912\n",
            "Epoch 6/10\n",
            "12/12 [==============================] - 3s 232ms/step - loss: 0.3360 - accuracy: 0.8425 - val_loss: 0.4094 - val_accuracy: 0.8132\n",
            "Epoch 7/10\n",
            "12/12 [==============================] - 5s 395ms/step - loss: 0.2982 - accuracy: 0.8812 - val_loss: 0.3673 - val_accuracy: 0.7912\n",
            "Epoch 8/10\n",
            "12/12 [==============================] - 4s 369ms/step - loss: 0.2688 - accuracy: 0.8812 - val_loss: 0.3633 - val_accuracy: 0.8022\n",
            "Epoch 9/10\n",
            "12/12 [==============================] - 4s 357ms/step - loss: 0.2162 - accuracy: 0.9171 - val_loss: 0.3593 - val_accuracy: 0.8132\n",
            "Epoch 10/10\n",
            "12/12 [==============================] - 4s 364ms/step - loss: 0.2176 - accuracy: 0.9061 - val_loss: 0.3613 - val_accuracy: 0.8132\n",
            "5/5 [==============================] - 0s 51ms/step - loss: 0.4187 - accuracy: 0.8278\n",
            "Epoch 1/10\n",
            "12/12 [==============================] - 3s 100ms/step - loss: 0.5890 - accuracy: 0.7348 - val_loss: 0.3610 - val_accuracy: 0.8681\n",
            "Epoch 2/10\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 0.4167 - accuracy: 0.8039 - val_loss: 0.3526 - val_accuracy: 0.8681\n",
            "Epoch 3/10\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 0.3528 - accuracy: 0.8232 - val_loss: 0.3382 - val_accuracy: 0.8462\n",
            "Epoch 4/10\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 0.2827 - accuracy: 0.8867 - val_loss: 0.3233 - val_accuracy: 0.8462\n",
            "Epoch 5/10\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 0.2611 - accuracy: 0.8840 - val_loss: 0.3220 - val_accuracy: 0.8791\n",
            "Epoch 6/10\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 0.1831 - accuracy: 0.9254 - val_loss: 0.3244 - val_accuracy: 0.8791\n",
            "Epoch 7/10\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 0.1368 - accuracy: 0.9669 - val_loss: 0.3133 - val_accuracy: 0.8681\n",
            "Epoch 8/10\n",
            "12/12 [==============================] - 1s 50ms/step - loss: 0.1392 - accuracy: 0.9448 - val_loss: 0.3407 - val_accuracy: 0.8901\n",
            "Epoch 9/10\n",
            "12/12 [==============================] - 1s 48ms/step - loss: 0.0954 - accuracy: 0.9669 - val_loss: 0.3657 - val_accuracy: 0.8462\n",
            "Epoch 10/10\n",
            "12/12 [==============================] - 1s 49ms/step - loss: 0.0732 - accuracy: 0.9807 - val_loss: 0.3994 - val_accuracy: 0.8681\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.4591 - accuracy: 0.8344\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Printing results\n",
        "print(\"Model 1 - Loss:\", loss_1, \"Accuracy:\", acc_1)\n",
        "print(\"Model 2 - Loss:\", loss_2, \"Accuracy:\", acc_2)\n",
        "print(\"Model 3 - Loss:\", loss_3, \"Accuracy:\", acc_3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v1bha3DEZK4S",
        "outputId": "6aeda8c0-44a5-4753-c7a8-260736e27b92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model 1 - Loss: 0.3705005645751953 Accuracy: 0.8410596251487732\n",
            "Model 2 - Loss: 0.41870689392089844 Accuracy: 0.8278145790100098\n",
            "Model 3 - Loss: 0.45913276076316833 Accuracy: 0.8344370722770691\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Definition of Artificial Neural Networks (ANNs)**\n",
        "Artificial Neural Networks (ANNs) are a foundational construct in the field of machine learning and deep learning, inspired by the biological neural networks that constitute animal brains. An ANN is composed of interconnected units or nodes called artificial neurons, which loosely model the neurons in a biological brain. Each connection between neurons can transmit a signal from one neuron to another, and the receiving neuron processes the signal and signals downstream neurons connected to it. Neurons are organized in layers: input layers to receive signals, hidden layers to process signals, and an output layer to make a prediction or decision. ANNs are capable of learning complex patterns and relationships in data by adjusting the weights of connections through a process known as training.\n",
        "\n",
        "### **ANNs in the Context of PD Speech Data**\n",
        "In the context of PD (Parkinson's Disease) speech data analysis, ANNs are used to identify patterns and characteristics in speech that are indicative of Parkinson's Disease. Here’s how ANNs typically function in this scenario:\n",
        "\n",
        "* Handling Sequential Data: Although ANNs are not inherently sequential like RNNs, they can still process speech data. This is usually done by transforming the speech into a suitable format, such as extracting features like Mel-frequency cepstral coefficients (MFCCs), pitch, tone, and amplitude.\n",
        "\n",
        "* Feature Learning: ANNs learn to identify patterns and relationships in the speech data during the training process. The hidden layers of an ANN can capture complex relationships in the data, making them powerful for tasks like speech analysis where the input features may have intricate interdependencies.\n",
        "\n",
        "* Classification or Regression Tasks: In the case of PD speech datasets, the typical task is to classify speech samples as indicative of either PD or a non-PD condition. ANNs achieve this through their output layer, which makes predictions based on the learned patterns in the data.\n",
        "\n",
        "* Flexibility in Architecture: The architecture of an ANN can be varied (number of layers, number of neurons per layer) to suit the complexity of the task. For PD speech data, this flexibility allows for fine-tuning the network to better capture the nuances of speech affected by PD.\n",
        "\n",
        "* Training and Optimization: ANNs are trained using backpropagation and gradient descent algorithms, where the model iteratively adjusts its weights to minimize the difference between the predicted output and the actual output. This training process is crucial for the network to learn the specific features of PD in speech data.\n",
        "\n",
        "In summary, ANNs are utilized for PD speech data analysis by transforming the speech into a feature set that the network can process, learning complex relationships within this data, and ultimately classifying speech samples based on the presence or absence of Parkinson's Disease characteristics. The flexibility in designing the network and the power to learn intricate patterns make ANNs a valuable tool in speech analysis and other similar tasks."
      ],
      "metadata": {
        "id": "eE_1jy9aW7Rc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating different types of ANNs and evaluating their results"
      ],
      "metadata": {
        "id": "04RzAzGAXja1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_ann_model_1(input_shape):\n",
        "    # Simple ANN model\n",
        "    model = Sequential([\n",
        "        Dense(64, activation='relu', input_shape=input_shape),\n",
        "        Dropout(0.5),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def create_ann_model_2(input_shape):\n",
        "    # ANN model with more neurons\n",
        "    model = Sequential([\n",
        "        Dense(128, activation='relu', input_shape=input_shape),\n",
        "        Dropout(0.5),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def create_ann_model_3(input_shape):\n",
        "    # ANN model with deeper layers\n",
        "    model = Sequential([\n",
        "        Dense(128, activation='relu', input_shape=input_shape),\n",
        "        Dropout(0.5),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(32, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Function to train and evaluate a model\n",
        "def train_and_evaluate_model(model, X_train, y_train, X_test, y_test, epochs=10, batch_size=32):\n",
        "    model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_split=0.2)\n",
        "    test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "    return test_loss, test_accuracy\n",
        "\n",
        "# Creating models\n",
        "input_shape = (X_train.shape[1],)\n",
        "model_1 = create_ann_model_1(input_shape)\n",
        "model_2 = create_ann_model_2(input_shape)\n",
        "model_3 = create_ann_model_3(input_shape)\n",
        "\n",
        "# Training and evaluating models\n",
        "loss_1, acc_1 = train_and_evaluate_model(model_1, X_train, y_train, X_test, y_test)\n",
        "loss_2, acc_2 = train_and_evaluate_model(model_2, X_train, y_train, X_test, y_test)\n",
        "loss_3, acc_3 = train_and_evaluate_model(model_3, X_train, y_train, X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wEQSBLpVZGuS",
        "outputId": "a4609e76-0ce8-4498-80fb-10e3a573021f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "12/12 [==============================] - 1s 23ms/step - loss: 0.7227 - accuracy: 0.6796 - val_loss: 0.4748 - val_accuracy: 0.7802\n",
            "Epoch 2/10\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.5198 - accuracy: 0.7597 - val_loss: 0.4393 - val_accuracy: 0.7692\n",
            "Epoch 3/10\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.5318 - accuracy: 0.7652 - val_loss: 0.4031 - val_accuracy: 0.7912\n",
            "Epoch 4/10\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.5235 - accuracy: 0.7762 - val_loss: 0.4083 - val_accuracy: 0.8242\n",
            "Epoch 5/10\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4380 - accuracy: 0.7735 - val_loss: 0.3875 - val_accuracy: 0.8022\n",
            "Epoch 6/10\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4249 - accuracy: 0.8315 - val_loss: 0.3574 - val_accuracy: 0.8132\n",
            "Epoch 7/10\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3169 - accuracy: 0.8619 - val_loss: 0.3419 - val_accuracy: 0.8242\n",
            "Epoch 8/10\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3191 - accuracy: 0.8425 - val_loss: 0.3377 - val_accuracy: 0.8242\n",
            "Epoch 9/10\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2943 - accuracy: 0.8702 - val_loss: 0.3220 - val_accuracy: 0.8242\n",
            "Epoch 10/10\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2802 - accuracy: 0.8674 - val_loss: 0.2917 - val_accuracy: 0.8571\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3324 - accuracy: 0.8411\n",
            "Epoch 1/10\n",
            "12/12 [==============================] - 1s 34ms/step - loss: 0.8031 - accuracy: 0.6077 - val_loss: 0.4076 - val_accuracy: 0.8571\n",
            "Epoch 2/10\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.5002 - accuracy: 0.7790 - val_loss: 0.3788 - val_accuracy: 0.8242\n",
            "Epoch 3/10\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.4337 - accuracy: 0.8011 - val_loss: 0.3602 - val_accuracy: 0.8352\n",
            "Epoch 4/10\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.3794 - accuracy: 0.8453 - val_loss: 0.3399 - val_accuracy: 0.8462\n",
            "Epoch 5/10\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.3468 - accuracy: 0.8177 - val_loss: 0.3122 - val_accuracy: 0.8462\n",
            "Epoch 6/10\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.2902 - accuracy: 0.8757 - val_loss: 0.2937 - val_accuracy: 0.8571\n",
            "Epoch 7/10\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.3146 - accuracy: 0.8674 - val_loss: 0.2812 - val_accuracy: 0.8901\n",
            "Epoch 8/10\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.2427 - accuracy: 0.9088 - val_loss: 0.2870 - val_accuracy: 0.8791\n",
            "Epoch 9/10\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.2127 - accuracy: 0.9144 - val_loss: 0.2692 - val_accuracy: 0.9011\n",
            "Epoch 10/10\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.2126 - accuracy: 0.9282 - val_loss: 0.2579 - val_accuracy: 0.9011\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3573 - accuracy: 0.8675\n",
            "Epoch 1/10\n",
            "12/12 [==============================] - 2s 25ms/step - loss: 0.8283 - accuracy: 0.6215 - val_loss: 0.5085 - val_accuracy: 0.8132\n",
            "Epoch 2/10\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.7457 - accuracy: 0.6657 - val_loss: 0.4506 - val_accuracy: 0.8242\n",
            "Epoch 3/10\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.6376 - accuracy: 0.7072 - val_loss: 0.4400 - val_accuracy: 0.8022\n",
            "Epoch 4/10\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.5872 - accuracy: 0.7403 - val_loss: 0.4458 - val_accuracy: 0.7692\n",
            "Epoch 5/10\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.5740 - accuracy: 0.7044 - val_loss: 0.4269 - val_accuracy: 0.7912\n",
            "Epoch 6/10\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.5925 - accuracy: 0.7376 - val_loss: 0.4361 - val_accuracy: 0.8132\n",
            "Epoch 7/10\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.5023 - accuracy: 0.7624 - val_loss: 0.4176 - val_accuracy: 0.8462\n",
            "Epoch 8/10\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.4425 - accuracy: 0.8011 - val_loss: 0.4085 - val_accuracy: 0.8352\n",
            "Epoch 9/10\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.4249 - accuracy: 0.8066 - val_loss: 0.3881 - val_accuracy: 0.8352\n",
            "Epoch 10/10\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.4220 - accuracy: 0.7983 - val_loss: 0.3648 - val_accuracy: 0.8571\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3613 - accuracy: 0.8940\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Printing results\n",
        "print(\"Model 1 - Loss:\", loss_1, \"Accuracy:\", acc_1)\n",
        "print(\"Model 2 - Loss:\", loss_2, \"Accuracy:\", acc_2)\n",
        "print(\"Model 3 - Loss:\", loss_3, \"Accuracy:\", acc_3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HBGMsCJDZNEJ",
        "outputId": "6e7186b4-2437-4bf8-92e8-ea55c9ec0db8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model 1 - Loss: 0.33235326409339905 Accuracy: 0.8410596251487732\n",
            "Model 2 - Loss: 0.3572838008403778 Accuracy: 0.8675496578216553\n",
            "Model 3 - Loss: 0.3612525761127472 Accuracy: 0.8940397500991821\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Definition of Recurrent Neural Networks (RNNs)**\n",
        "Recurrent Neural Networks (RNNs) are a class of artificial neural networks designed to recognize patterns in sequences of data, such as text, genomes, handwriting, or time series data. Unlike standard feedforward neural networks, RNNs have a unique feature called loops, allowing information to persist. In an RNN, connections between nodes form a directed graph along a temporal sequence, enabling it to exhibit temporal dynamic behavior. This architecture makes them particularly well-suited for tasks where context and order in time are relevant.\n",
        "\n",
        "### **RNNs in the Context of PD Speech Data**\n",
        "When applying RNNs to PD (Parkinson's Disease) speech data, the focus is on capturing the temporal dynamics and contextual relationships within the speech. Here’s how RNNs function in this scenario:\n",
        "\n",
        "* Temporal Feature Learning: RNNs are inherently suited for sequential data, making them ideal for speech analysis. They can process speech data as a sequence of time-based features, learning important temporal characteristics like changes in tone, pace, or intonation that might be indicative of PD.\n",
        "\n",
        "* Capturing Dependencies Over Time: One of the key strengths of RNNs is their ability to connect previous information to the current task, which is crucial for speech data where the context and sequence of sounds carry significant information.\n",
        "\n",
        "* Handling Variable-Length Input: Speech samples can vary in length, and RNNs can handle such variable-length input sequences effectively. This is particularly important for analyzing continuous speech data in a clinical setting where the speech duration may not be fixed.\n",
        "\n",
        "* Sequence to Sequence Mapping: RNNs can map sequences to sequences, making them suitable for tasks like speech recognition or synthesis, and in the context of PD, for analyzing continuous speech patterns for signs of the disease.\n",
        "\n",
        "* Challenges and Enhancements: Vanilla RNNs often suffer from problems like vanishing and exploding gradients. To mitigate these issues, advanced variants like LSTM (Long Short-Term Memory) and GRU (Gated Recurrent Units) are used. These models are better at capturing long-range dependencies and are more robust in training.\n",
        "\n",
        "* Classification or Regression Tasks: In PD speech analysis, RNNs can be used for binary classification (PD or non-PD), or even for more nuanced tasks like staging the severity of PD based on speech characteristics.\n",
        "\n",
        "* In summary, RNNs' ability to process sequential speech data, capture temporal dependencies, and handle variable-length input makes them particularly well-suited for analyzing PD speech data. By learning the intricate patterns and temporal sequences in speech affected by Parkinson's Disease, RNNs can play a crucial role in automated diagnostics and patient monitoring systems."
      ],
      "metadata": {
        "id": "Uemb7FQtYQAM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating different types of RNNs and evaluating their results"
      ],
      "metadata": {
        "id": "gvtgQX7-ZSbO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_rnn_model(input_shape):\n",
        "    # Simple RNN model\n",
        "    model = Sequential([\n",
        "        SimpleRNN(64, return_sequences=True, input_shape=input_shape),\n",
        "        SimpleRNN(64),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def create_lstm_model(input_shape):\n",
        "    # LSTM model\n",
        "    model = Sequential([\n",
        "        LSTM(64, return_sequences=True, input_shape=input_shape),\n",
        "        LSTM(64),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def create_gru_model(input_shape):\n",
        "    # GRU model\n",
        "    model = Sequential([\n",
        "        GRU(64, return_sequences=True, input_shape=input_shape),\n",
        "        GRU(64),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Function to train and evaluate a model\n",
        "def train_and_evaluate_model(model, X_train, y_train, X_test, y_test, epochs=10, batch_size=32):\n",
        "    model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_split=0.2)\n",
        "    test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "    return test_loss, test_accuracy\n",
        "\n",
        "# Creating models\n",
        "input_shape = (X_train.shape[1], X_train.shape[2])\n",
        "rnn_model = create_rnn_model(input_shape)\n",
        "lstm_model = create_lstm_model(input_shape)\n",
        "gru_model = create_gru_model(input_shape)\n",
        "\n",
        "# Training and evaluating models\n",
        "rnn_loss, rnn_acc = train_and_evaluate_model(rnn_model, X_train, y_train, X_test, y_test)\n",
        "lstm_loss, lstm_acc = train_and_evaluate_model(lstm_model, X_train, y_train, X_test, y_test)\n",
        "gru_loss, gru_acc = train_and_evaluate_model(gru_model, X_train, y_train, X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gAh8dVackIVS",
        "outputId": "6c123b11-3fd2-491a-b9f1-00ac392031f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "12/12 [==============================] - 8s 442ms/step - loss: 0.5780 - accuracy: 0.6989 - val_loss: 0.4446 - val_accuracy: 0.7912\n",
            "Epoch 2/10\n",
            "12/12 [==============================] - 6s 451ms/step - loss: 0.4847 - accuracy: 0.7597 - val_loss: 0.4155 - val_accuracy: 0.7692\n",
            "Epoch 3/10\n",
            "12/12 [==============================] - 4s 361ms/step - loss: 0.4743 - accuracy: 0.7818 - val_loss: 0.4163 - val_accuracy: 0.7692\n",
            "Epoch 4/10\n",
            "12/12 [==============================] - 5s 440ms/step - loss: 0.4758 - accuracy: 0.7680 - val_loss: 0.4192 - val_accuracy: 0.8352\n",
            "Epoch 5/10\n",
            "12/12 [==============================] - 6s 441ms/step - loss: 0.4310 - accuracy: 0.7901 - val_loss: 0.3752 - val_accuracy: 0.8681\n",
            "Epoch 6/10\n",
            "12/12 [==============================] - 4s 329ms/step - loss: 0.4089 - accuracy: 0.8122 - val_loss: 0.3650 - val_accuracy: 0.8681\n",
            "Epoch 7/10\n",
            "12/12 [==============================] - 5s 426ms/step - loss: 0.3857 - accuracy: 0.8177 - val_loss: 0.3714 - val_accuracy: 0.8352\n",
            "Epoch 8/10\n",
            "12/12 [==============================] - 6s 468ms/step - loss: 0.3886 - accuracy: 0.8177 - val_loss: 0.3603 - val_accuracy: 0.8462\n",
            "Epoch 9/10\n",
            "12/12 [==============================] - 4s 319ms/step - loss: 0.4069 - accuracy: 0.8011 - val_loss: 0.3882 - val_accuracy: 0.8242\n",
            "Epoch 10/10\n",
            "12/12 [==============================] - 5s 397ms/step - loss: 0.3973 - accuracy: 0.8122 - val_loss: 0.3829 - val_accuracy: 0.8352\n",
            "5/5 [==============================] - 1s 156ms/step - loss: 0.4231 - accuracy: 0.8278\n",
            "Epoch 1/10\n",
            "12/12 [==============================] - 18s 1s/step - loss: 0.6673 - accuracy: 0.7099 - val_loss: 0.6120 - val_accuracy: 0.8022\n",
            "Epoch 2/10\n",
            "12/12 [==============================] - 11s 897ms/step - loss: 0.6051 - accuracy: 0.7348 - val_loss: 0.5380 - val_accuracy: 0.8022\n",
            "Epoch 3/10\n",
            "12/12 [==============================] - 11s 850ms/step - loss: 0.5639 - accuracy: 0.7431 - val_loss: 0.5066 - val_accuracy: 0.8022\n",
            "Epoch 4/10\n",
            "12/12 [==============================] - 12s 978ms/step - loss: 0.5310 - accuracy: 0.7652 - val_loss: 0.4854 - val_accuracy: 0.8022\n",
            "Epoch 5/10\n",
            "12/12 [==============================] - 12s 993ms/step - loss: 0.5049 - accuracy: 0.7680 - val_loss: 0.4656 - val_accuracy: 0.8132\n",
            "Epoch 6/10\n",
            "12/12 [==============================] - 12s 982ms/step - loss: 0.4985 - accuracy: 0.7762 - val_loss: 0.4377 - val_accuracy: 0.8132\n",
            "Epoch 7/10\n",
            "12/12 [==============================] - 10s 828ms/step - loss: 0.4950 - accuracy: 0.7707 - val_loss: 0.4586 - val_accuracy: 0.8132\n",
            "Epoch 8/10\n",
            "12/12 [==============================] - 12s 973ms/step - loss: 0.4701 - accuracy: 0.7790 - val_loss: 0.4435 - val_accuracy: 0.8462\n",
            "Epoch 9/10\n",
            "12/12 [==============================] - 12s 981ms/step - loss: 0.4589 - accuracy: 0.7956 - val_loss: 0.4358 - val_accuracy: 0.8462\n",
            "Epoch 10/10\n",
            "12/12 [==============================] - 11s 976ms/step - loss: 0.4510 - accuracy: 0.8039 - val_loss: 0.4275 - val_accuracy: 0.8462\n",
            "5/5 [==============================] - 1s 193ms/step - loss: 0.4217 - accuracy: 0.8344\n",
            "Epoch 1/10\n",
            "12/12 [==============================] - 17s 1s/step - loss: 0.6656 - accuracy: 0.6436 - val_loss: 0.5831 - val_accuracy: 0.8022\n",
            "Epoch 2/10\n",
            "12/12 [==============================] - 11s 946ms/step - loss: 0.5747 - accuracy: 0.7376 - val_loss: 0.4877 - val_accuracy: 0.8022\n",
            "Epoch 3/10\n",
            "12/12 [==============================] - 9s 765ms/step - loss: 0.5549 - accuracy: 0.7541 - val_loss: 0.4450 - val_accuracy: 0.8242\n",
            "Epoch 4/10\n",
            "12/12 [==============================] - 11s 959ms/step - loss: 0.5279 - accuracy: 0.7652 - val_loss: 0.4561 - val_accuracy: 0.8242\n",
            "Epoch 5/10\n",
            "12/12 [==============================] - 11s 976ms/step - loss: 0.5168 - accuracy: 0.7790 - val_loss: 0.4327 - val_accuracy: 0.8242\n",
            "Epoch 6/10\n",
            "12/12 [==============================] - 11s 906ms/step - loss: 0.5001 - accuracy: 0.7624 - val_loss: 0.4149 - val_accuracy: 0.8132\n",
            "Epoch 7/10\n",
            "12/12 [==============================] - 10s 793ms/step - loss: 0.4934 - accuracy: 0.7762 - val_loss: 0.4006 - val_accuracy: 0.8132\n",
            "Epoch 8/10\n",
            "12/12 [==============================] - 12s 993ms/step - loss: 0.4929 - accuracy: 0.7790 - val_loss: 0.3941 - val_accuracy: 0.8132\n",
            "Epoch 9/10\n",
            "12/12 [==============================] - 12s 980ms/step - loss: 0.4907 - accuracy: 0.7818 - val_loss: 0.3979 - val_accuracy: 0.8242\n",
            "Epoch 10/10\n",
            "12/12 [==============================] - 11s 930ms/step - loss: 0.4835 - accuracy: 0.7652 - val_loss: 0.3985 - val_accuracy: 0.8352\n",
            "5/5 [==============================] - 1s 157ms/step - loss: 0.4541 - accuracy: 0.7947\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Printing results\n",
        "print(\"RNN Model - Loss:\", rnn_loss, \"Accuracy:\", rnn_acc)\n",
        "print(\"LSTM Model - Loss:\", lstm_loss, \"Accuracy:\", lstm_acc)\n",
        "print(\"GRU Model - Loss:\", gru_loss, \"Accuracy:\", gru_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EIkVeji8kOp2",
        "outputId": "6f6b296e-33ef-4b92-bea0-885accab09ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RNN Model - Loss: 0.4230723977088928 Accuracy: 0.8278145790100098\n",
            "LSTM Model - Loss: 0.4217391908168793 Accuracy: 0.8344370722770691\n",
            "GRU Model - Loss: 0.4541018009185791 Accuracy: 0.7947019934654236\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Definition of Stacking**\n",
        "Stacking, short for \"stacked generalization,\" is an ensemble machine learning technique that combines multiple models to improve prediction accuracy. The key idea in stacking is to use a new model, known as the meta-model or blender, to learn how to best integrate the predictions of several base models.\n",
        "\n",
        "In stacking, the initial level (or base level) consists of a variety of models which are trained on the full training dataset. These models can be diverse and include different types of machine learning algorithms. Each of these base models then makes predictions, but instead of using these predictions directly for the final output, they are used as input features for the next level.\n",
        "\n",
        "### **Definition of Meta-Model**\n",
        "The meta-model, which sits at the second level (or meta level), is trained on the outputs of the base models. The input to the meta-model is typically the predictions made by the base models on a holdout set (a portion of the training set not used to train the base models), and its output is the final prediction. The meta-model essentially learns the best way to combine the predictions from the base models to make a more accurate and robust prediction than any single base model could on its own."
      ],
      "metadata": {
        "id": "W8VKc_g3Z4ei"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Doing Stacking of CNNs and Creating Meta Models(Logistic Regression, Random Forest, XGBoost, SVM and CNN)"
      ],
      "metadata": {
        "id": "jTSJDE8RbE3v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Logistic Regression"
      ],
      "metadata": {
        "id": "PGgA_Oq7dgkL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to generate predictions for stacking\n",
        "def generate_predictions(model, X):\n",
        "    return model.predict(X).reshape(-1, 1)\n",
        "\n",
        "# Training the CNN models\n",
        "model_1 = create_cnn_model_1(input_shape)\n",
        "model_2 = create_cnn_model_2(input_shape)\n",
        "model_3 = create_cnn_model_3(input_shape)\n",
        "\n",
        "# Training and generating predictions\n",
        "model_1.fit(X_train, y_train, epochs=epochs, batch_size=batch_size)\n",
        "model_2.fit(X_train, y_train, epochs=epochs, batch_size=batch_size)\n",
        "model_3.fit(X_train, y_train, epochs=epochs, batch_size=batch_size)\n",
        "\n",
        "predictions_1 = generate_predictions(model_1, X_val)\n",
        "predictions_2 = generate_predictions(model_2, X_val)\n",
        "predictions_3 = generate_predictions(model_3, X_val)\n",
        "\n",
        "# Stacking the predictions\n",
        "stacked_predictions = np.hstack((predictions_1, predictions_2, predictions_3))\n",
        "\n",
        "# Training meta-model on the stacked predictions\n",
        "meta_model_lr = LogisticRegression()\n",
        "meta_model_lr.fit(stacked_predictions, y_val)\n",
        "\n",
        "\n",
        "# Evaluating the meta-model on the test set\n",
        "# First, getting predictions from the base models on the test set\n",
        "test_predictions_1 = generate_predictions(model_1, X_test)\n",
        "test_predictions_2 = generate_predictions(model_2, X_test)\n",
        "test_predictions_3 = generate_predictions(model_3, X_test)\n",
        "\n",
        "# Stacking the test set predictions\n",
        "stacked_test_predictions = np.hstack((test_predictions_1, test_predictions_2, test_predictions_3))\n",
        "\n",
        "# Making final predictions with the meta-model\n",
        "final_predictions_lr = meta_model_lr.predict(stacked_test_predictions)\n",
        "\n",
        "# Evaluating accuracy\n",
        "accuracy_lr = accuracy_score(y_test, final_predictions_lr)\n",
        "print(\"Stacking with Logistic Regression - Accuracy:\", accuracy_lr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uvOlW_VdGAMV",
        "outputId": "b1873a3e-4419-425d-ae15-e1290c51823d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "6/6 [==============================] - 1s 72ms/step - loss: 0.7363 - accuracy: 0.7351\n",
            "Epoch 2/25\n",
            "6/6 [==============================] - 0s 67ms/step - loss: 0.5109 - accuracy: 0.8234\n",
            "Epoch 3/25\n",
            "6/6 [==============================] - 0s 66ms/step - loss: 0.4248 - accuracy: 0.7704\n",
            "Epoch 4/25\n",
            "6/6 [==============================] - 0s 64ms/step - loss: 0.3531 - accuracy: 0.8411\n",
            "Epoch 5/25\n",
            "6/6 [==============================] - 0s 64ms/step - loss: 0.3578 - accuracy: 0.8411\n",
            "Epoch 6/25\n",
            "6/6 [==============================] - 0s 83ms/step - loss: 0.2910 - accuracy: 0.8698\n",
            "Epoch 7/25\n",
            "6/6 [==============================] - 1s 95ms/step - loss: 0.2847 - accuracy: 0.8720\n",
            "Epoch 8/25\n",
            "6/6 [==============================] - 1s 95ms/step - loss: 0.2460 - accuracy: 0.8918\n",
            "Epoch 9/25\n",
            "6/6 [==============================] - 1s 85ms/step - loss: 0.2255 - accuracy: 0.9161\n",
            "Epoch 10/25\n",
            "6/6 [==============================] - 1s 88ms/step - loss: 0.2158 - accuracy: 0.9183\n",
            "Epoch 11/25\n",
            "6/6 [==============================] - 1s 107ms/step - loss: 0.1794 - accuracy: 0.9294\n",
            "Epoch 12/25\n",
            "6/6 [==============================] - 1s 89ms/step - loss: 0.1570 - accuracy: 0.9404\n",
            "Epoch 13/25\n",
            "6/6 [==============================] - 1s 85ms/step - loss: 0.1388 - accuracy: 0.9514\n",
            "Epoch 14/25\n",
            "6/6 [==============================] - 0s 81ms/step - loss: 0.1309 - accuracy: 0.9448\n",
            "Epoch 15/25\n",
            "6/6 [==============================] - 0s 69ms/step - loss: 0.1192 - accuracy: 0.9669\n",
            "Epoch 16/25\n",
            "6/6 [==============================] - 0s 53ms/step - loss: 0.0968 - accuracy: 0.9735\n",
            "Epoch 17/25\n",
            "6/6 [==============================] - 0s 52ms/step - loss: 0.0949 - accuracy: 0.9669\n",
            "Epoch 18/25\n",
            "6/6 [==============================] - 0s 53ms/step - loss: 0.0935 - accuracy: 0.9691\n",
            "Epoch 19/25\n",
            "6/6 [==============================] - 0s 52ms/step - loss: 0.0846 - accuracy: 0.9669\n",
            "Epoch 20/25\n",
            "6/6 [==============================] - 0s 55ms/step - loss: 0.0779 - accuracy: 0.9713\n",
            "Epoch 21/25\n",
            "6/6 [==============================] - 0s 55ms/step - loss: 0.0598 - accuracy: 0.9912\n",
            "Epoch 22/25\n",
            "6/6 [==============================] - 0s 52ms/step - loss: 0.0625 - accuracy: 0.9912\n",
            "Epoch 23/25\n",
            "6/6 [==============================] - 0s 60ms/step - loss: 0.0470 - accuracy: 0.9956\n",
            "Epoch 24/25\n",
            "6/6 [==============================] - 0s 64ms/step - loss: 0.0496 - accuracy: 0.9890\n",
            "Epoch 25/25\n",
            "6/6 [==============================] - 0s 60ms/step - loss: 0.0477 - accuracy: 0.9912\n",
            "Epoch 1/25\n",
            "6/6 [==============================] - 5s 420ms/step - loss: 3.4335 - accuracy: 0.7461\n",
            "Epoch 2/25\n",
            "6/6 [==============================] - 3s 431ms/step - loss: 1.6934 - accuracy: 0.7770\n",
            "Epoch 3/25\n",
            "6/6 [==============================] - 3s 466ms/step - loss: 1.2694 - accuracy: 0.7704\n",
            "Epoch 4/25\n",
            "6/6 [==============================] - 4s 594ms/step - loss: 0.7183 - accuracy: 0.8013\n",
            "Epoch 5/25\n",
            "6/6 [==============================] - 2s 361ms/step - loss: 0.4005 - accuracy: 0.8411\n",
            "Epoch 6/25\n",
            "6/6 [==============================] - 2s 357ms/step - loss: 0.3848 - accuracy: 0.8565\n",
            "Epoch 7/25\n",
            "6/6 [==============================] - 2s 355ms/step - loss: 0.2744 - accuracy: 0.8764\n",
            "Epoch 8/25\n",
            "6/6 [==============================] - 2s 389ms/step - loss: 0.2572 - accuracy: 0.8830\n",
            "Epoch 9/25\n",
            "6/6 [==============================] - 3s 560ms/step - loss: 0.2361 - accuracy: 0.9073\n",
            "Epoch 10/25\n",
            "6/6 [==============================] - 4s 596ms/step - loss: 0.2013 - accuracy: 0.9404\n",
            "Epoch 11/25\n",
            "6/6 [==============================] - 3s 416ms/step - loss: 0.1894 - accuracy: 0.9183\n",
            "Epoch 12/25\n",
            "6/6 [==============================] - 3s 458ms/step - loss: 0.2198 - accuracy: 0.9249\n",
            "Epoch 13/25\n",
            "6/6 [==============================] - 3s 425ms/step - loss: 0.1449 - accuracy: 0.9426\n",
            "Epoch 14/25\n",
            "6/6 [==============================] - 3s 502ms/step - loss: 0.1535 - accuracy: 0.9514\n",
            "Epoch 15/25\n",
            "6/6 [==============================] - 4s 618ms/step - loss: 0.0919 - accuracy: 0.9735\n",
            "Epoch 16/25\n",
            "6/6 [==============================] - 3s 424ms/step - loss: 0.1104 - accuracy: 0.9669\n",
            "Epoch 17/25\n",
            "6/6 [==============================] - 2s 378ms/step - loss: 0.0771 - accuracy: 0.9757\n",
            "Epoch 18/25\n",
            "6/6 [==============================] - 2s 359ms/step - loss: 0.0652 - accuracy: 0.9868\n",
            "Epoch 19/25\n",
            "6/6 [==============================] - 3s 454ms/step - loss: 0.0598 - accuracy: 0.9845\n",
            "Epoch 20/25\n",
            "6/6 [==============================] - 4s 686ms/step - loss: 0.0528 - accuracy: 0.9890\n",
            "Epoch 21/25\n",
            "6/6 [==============================] - 3s 463ms/step - loss: 0.0483 - accuracy: 0.9934\n",
            "Epoch 22/25\n",
            "6/6 [==============================] - 3s 464ms/step - loss: 0.0497 - accuracy: 0.9845\n",
            "Epoch 23/25\n",
            "6/6 [==============================] - 3s 436ms/step - loss: 0.0460 - accuracy: 0.9823\n",
            "Epoch 24/25\n",
            "6/6 [==============================] - 3s 429ms/step - loss: 0.0445 - accuracy: 0.9934\n",
            "Epoch 25/25\n",
            "6/6 [==============================] - 4s 703ms/step - loss: 0.0358 - accuracy: 0.9956\n",
            "Epoch 1/25\n",
            "6/6 [==============================] - 2s 94ms/step - loss: 0.5948 - accuracy: 0.7241\n",
            "Epoch 2/25\n",
            "6/6 [==============================] - 1s 88ms/step - loss: 0.4674 - accuracy: 0.8146\n",
            "Epoch 3/25\n",
            "6/6 [==============================] - 1s 93ms/step - loss: 0.4006 - accuracy: 0.8168\n",
            "Epoch 4/25\n",
            "6/6 [==============================] - 1s 100ms/step - loss: 0.3445 - accuracy: 0.8609\n",
            "Epoch 5/25\n",
            "6/6 [==============================] - 1s 102ms/step - loss: 0.3071 - accuracy: 0.8543\n",
            "Epoch 6/25\n",
            "6/6 [==============================] - 1s 100ms/step - loss: 0.2589 - accuracy: 0.8786\n",
            "Epoch 7/25\n",
            "6/6 [==============================] - 1s 86ms/step - loss: 0.2315 - accuracy: 0.9007\n",
            "Epoch 8/25\n",
            "6/6 [==============================] - 1s 91ms/step - loss: 0.1945 - accuracy: 0.9205\n",
            "Epoch 9/25\n",
            "6/6 [==============================] - 1s 87ms/step - loss: 0.1609 - accuracy: 0.9404\n",
            "Epoch 10/25\n",
            "6/6 [==============================] - 1s 88ms/step - loss: 0.1358 - accuracy: 0.9536\n",
            "Epoch 11/25\n",
            "6/6 [==============================] - 1s 90ms/step - loss: 0.1052 - accuracy: 0.9713\n",
            "Epoch 12/25\n",
            "6/6 [==============================] - 1s 108ms/step - loss: 0.0719 - accuracy: 0.9845\n",
            "Epoch 13/25\n",
            "6/6 [==============================] - 1s 110ms/step - loss: 0.0677 - accuracy: 0.9823\n",
            "Epoch 14/25\n",
            "6/6 [==============================] - 1s 106ms/step - loss: 0.0586 - accuracy: 0.9890\n",
            "Epoch 15/25\n",
            "6/6 [==============================] - 1s 90ms/step - loss: 0.0451 - accuracy: 0.9934\n",
            "Epoch 16/25\n",
            "6/6 [==============================] - 1s 136ms/step - loss: 0.0487 - accuracy: 0.9823\n",
            "Epoch 17/25\n",
            "6/6 [==============================] - 1s 169ms/step - loss: 0.0407 - accuracy: 0.9934\n",
            "Epoch 18/25\n",
            "6/6 [==============================] - 1s 144ms/step - loss: 0.0290 - accuracy: 0.9978\n",
            "Epoch 19/25\n",
            "6/6 [==============================] - 1s 146ms/step - loss: 0.0242 - accuracy: 1.0000\n",
            "Epoch 20/25\n",
            "6/6 [==============================] - 1s 153ms/step - loss: 0.0242 - accuracy: 0.9934\n",
            "Epoch 21/25\n",
            "6/6 [==============================] - 1s 146ms/step - loss: 0.0133 - accuracy: 1.0000\n",
            "Epoch 22/25\n",
            "6/6 [==============================] - 1s 105ms/step - loss: 0.0125 - accuracy: 1.0000\n",
            "Epoch 23/25\n",
            "6/6 [==============================] - 1s 101ms/step - loss: 0.0106 - accuracy: 1.0000\n",
            "Epoch 24/25\n",
            "6/6 [==============================] - 1s 106ms/step - loss: 0.0099 - accuracy: 1.0000\n",
            "Epoch 25/25\n",
            "6/6 [==============================] - 1s 107ms/step - loss: 0.0095 - accuracy: 1.0000\n",
            "5/5 [==============================] - 0s 11ms/step\n",
            "5/5 [==============================] - 0s 37ms/step\n",
            "5/5 [==============================] - 0s 13ms/step\n",
            "5/5 [==============================] - 0s 10ms/step\n",
            "5/5 [==============================] - 0s 35ms/step\n",
            "5/5 [==============================] - 0s 12ms/step\n",
            "Stacking with Logistic Regression - Accuracy: 0.8410596026490066\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Random Forest"
      ],
      "metadata": {
        "id": "LEC1K5KDdlmc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to generate predictions for stacking\n",
        "def generate_predictions(model, X):\n",
        "    return model.predict(X).reshape(-1, 1)\n",
        "\n",
        "# Training the CNN models\n",
        "model_1 = create_cnn_model_1(input_shape)\n",
        "model_2 = create_cnn_model_2(input_shape)\n",
        "model_3 = create_cnn_model_3(input_shape)\n",
        "\n",
        "# Training and generating predictions\n",
        "model_1.fit(X_train, y_train, epochs=epochs, batch_size=batch_size)\n",
        "model_2.fit(X_train, y_train, epochs=epochs, batch_size=batch_size)\n",
        "model_3.fit(X_train, y_train, epochs=epochs, batch_size=batch_size)\n",
        "\n",
        "predictions_1 = generate_predictions(model_1, X_val)\n",
        "predictions_2 = generate_predictions(model_2, X_val)\n",
        "predictions_3 = generate_predictions(model_3, X_val)\n",
        "\n",
        "# Stacking the predictions\n",
        "stacked_predictions = np.hstack((predictions_1, predictions_2, predictions_3))\n",
        "\n",
        "# Training meta-model on the stacked predictions\n",
        "meta_model_rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "meta_model_rf.fit(stacked_predictions, y_val)\n",
        "\n",
        "# Evaluating the meta-model on the test set\n",
        "# First, getting predictions from the base models on the test set\n",
        "test_predictions_1 = generate_predictions(model_1, X_test)\n",
        "test_predictions_2 = generate_predictions(model_2, X_test)\n",
        "test_predictions_3 = generate_predictions(model_3, X_test)\n",
        "\n",
        "# Stacking the test set predictions\n",
        "stacked_test_predictions = np.hstack((test_predictions_1, test_predictions_2, test_predictions_3))\n",
        "\n",
        "# Making final predictions with the meta-model\n",
        "final_predictions_rf = meta_model_rf.predict(stacked_test_predictions)\n",
        "\n",
        "# Evaluating accuracy\n",
        "accuracy_rf = accuracy_score(y_test, final_predictions_rf)\n",
        "print(\"Stacking with Random Forest - Accuracy:\", accuracy_rf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ilMwOG3LJ7S",
        "outputId": "09a28a2a-d167-4fbd-9343-198db8514547"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "6/6 [==============================] - 1s 61ms/step - loss: 0.7506 - accuracy: 0.6909\n",
            "Epoch 2/25\n",
            "6/6 [==============================] - 0s 62ms/step - loss: 0.4793 - accuracy: 0.8102\n",
            "Epoch 3/25\n",
            "6/6 [==============================] - 0s 63ms/step - loss: 0.3996 - accuracy: 0.8256\n",
            "Epoch 4/25\n",
            "6/6 [==============================] - 0s 58ms/step - loss: 0.3493 - accuracy: 0.8565\n",
            "Epoch 5/25\n",
            "6/6 [==============================] - 0s 62ms/step - loss: 0.3179 - accuracy: 0.8631\n",
            "Epoch 6/25\n",
            "6/6 [==============================] - 0s 62ms/step - loss: 0.2917 - accuracy: 0.8587\n",
            "Epoch 7/25\n",
            "6/6 [==============================] - 0s 62ms/step - loss: 0.2524 - accuracy: 0.8940\n",
            "Epoch 8/25\n",
            "6/6 [==============================] - 0s 62ms/step - loss: 0.2470 - accuracy: 0.8918\n",
            "Epoch 9/25\n",
            "6/6 [==============================] - 0s 54ms/step - loss: 0.2168 - accuracy: 0.9095\n",
            "Epoch 10/25\n",
            "6/6 [==============================] - 0s 53ms/step - loss: 0.2022 - accuracy: 0.9205\n",
            "Epoch 11/25\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 0.1800 - accuracy: 0.9205\n",
            "Epoch 12/25\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.1546 - accuracy: 0.9316\n",
            "Epoch 13/25\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.1633 - accuracy: 0.9338\n",
            "Epoch 14/25\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 0.1307 - accuracy: 0.9625\n",
            "Epoch 15/25\n",
            "6/6 [==============================] - 0s 52ms/step - loss: 0.1220 - accuracy: 0.9691\n",
            "Epoch 16/25\n",
            "6/6 [==============================] - 0s 60ms/step - loss: 0.0992 - accuracy: 0.9625\n",
            "Epoch 17/25\n",
            "6/6 [==============================] - 0s 64ms/step - loss: 0.1060 - accuracy: 0.9603\n",
            "Epoch 18/25\n",
            "6/6 [==============================] - 0s 67ms/step - loss: 0.0838 - accuracy: 0.9823\n",
            "Epoch 19/25\n",
            "6/6 [==============================] - 1s 94ms/step - loss: 0.0899 - accuracy: 0.9779\n",
            "Epoch 20/25\n",
            "6/6 [==============================] - 1s 94ms/step - loss: 0.0726 - accuracy: 0.9890\n",
            "Epoch 21/25\n",
            "6/6 [==============================] - 1s 98ms/step - loss: 0.0599 - accuracy: 0.9890\n",
            "Epoch 22/25\n",
            "6/6 [==============================] - 1s 83ms/step - loss: 0.0585 - accuracy: 0.9912\n",
            "Epoch 23/25\n",
            "6/6 [==============================] - 1s 87ms/step - loss: 0.0599 - accuracy: 0.9956\n",
            "Epoch 24/25\n",
            "6/6 [==============================] - 1s 85ms/step - loss: 0.0755 - accuracy: 0.9823\n",
            "Epoch 25/25\n",
            "6/6 [==============================] - 0s 82ms/step - loss: 0.0547 - accuracy: 0.9845\n",
            "Epoch 1/25\n",
            "6/6 [==============================] - 5s 458ms/step - loss: 5.5707 - accuracy: 0.6269\n",
            "Epoch 2/25\n",
            "6/6 [==============================] - 2s 398ms/step - loss: 1.8314 - accuracy: 0.7461\n",
            "Epoch 3/25\n",
            "6/6 [==============================] - 3s 516ms/step - loss: 0.8796 - accuracy: 0.8013\n",
            "Epoch 4/25\n",
            "6/6 [==============================] - 5s 933ms/step - loss: 0.5417 - accuracy: 0.7770\n",
            "Epoch 5/25\n",
            "6/6 [==============================] - 3s 417ms/step - loss: 0.4032 - accuracy: 0.7991\n",
            "Epoch 6/25\n",
            "6/6 [==============================] - 2s 384ms/step - loss: 0.4171 - accuracy: 0.7837\n",
            "Epoch 7/25\n",
            "6/6 [==============================] - 3s 442ms/step - loss: 0.3782 - accuracy: 0.7947\n",
            "Epoch 8/25\n",
            "6/6 [==============================] - 3s 424ms/step - loss: 0.3723 - accuracy: 0.8057\n",
            "Epoch 9/25\n",
            "6/6 [==============================] - 4s 665ms/step - loss: 0.3809 - accuracy: 0.8013\n",
            "Epoch 10/25\n",
            "6/6 [==============================] - 3s 441ms/step - loss: 0.3406 - accuracy: 0.7947\n",
            "Epoch 11/25\n",
            "6/6 [==============================] - 3s 475ms/step - loss: 0.3295 - accuracy: 0.8124\n",
            "Epoch 12/25\n",
            "6/6 [==============================] - 3s 448ms/step - loss: 0.3286 - accuracy: 0.8079\n",
            "Epoch 13/25\n",
            "6/6 [==============================] - 2s 417ms/step - loss: 0.2959 - accuracy: 0.8433\n",
            "Epoch 14/25\n",
            "6/6 [==============================] - 4s 712ms/step - loss: 0.3084 - accuracy: 0.8300\n",
            "Epoch 15/25\n",
            "6/6 [==============================] - 3s 456ms/step - loss: 0.2768 - accuracy: 0.8521\n",
            "Epoch 16/25\n",
            "6/6 [==============================] - 3s 473ms/step - loss: 0.2720 - accuracy: 0.8344\n",
            "Epoch 17/25\n",
            "6/6 [==============================] - 3s 428ms/step - loss: 0.2705 - accuracy: 0.8499\n",
            "Epoch 18/25\n",
            "6/6 [==============================] - 3s 519ms/step - loss: 0.2523 - accuracy: 0.8653\n",
            "Epoch 19/25\n",
            "6/6 [==============================] - 4s 647ms/step - loss: 0.2582 - accuracy: 0.8609\n",
            "Epoch 20/25\n",
            "6/6 [==============================] - 2s 410ms/step - loss: 0.2692 - accuracy: 0.8587\n",
            "Epoch 21/25\n",
            "6/6 [==============================] - 2s 394ms/step - loss: 0.2187 - accuracy: 0.8808\n",
            "Epoch 22/25\n",
            "6/6 [==============================] - 3s 434ms/step - loss: 0.2210 - accuracy: 0.8852\n",
            "Epoch 23/25\n",
            "6/6 [==============================] - 3s 422ms/step - loss: 0.2139 - accuracy: 0.8852\n",
            "Epoch 24/25\n",
            "6/6 [==============================] - 4s 651ms/step - loss: 0.2508 - accuracy: 0.8985\n",
            "Epoch 25/25\n",
            "6/6 [==============================] - 3s 451ms/step - loss: 0.1949 - accuracy: 0.8918\n",
            "Epoch 1/25\n",
            "6/6 [==============================] - 2s 103ms/step - loss: 0.6965 - accuracy: 0.6358\n",
            "Epoch 2/25\n",
            "6/6 [==============================] - 1s 101ms/step - loss: 0.5064 - accuracy: 0.8013\n",
            "Epoch 3/25\n",
            "6/6 [==============================] - 1s 87ms/step - loss: 0.4155 - accuracy: 0.8212\n",
            "Epoch 4/25\n",
            "6/6 [==============================] - 1s 87ms/step - loss: 0.3958 - accuracy: 0.8212\n",
            "Epoch 5/25\n",
            "6/6 [==============================] - 1s 86ms/step - loss: 0.3420 - accuracy: 0.8477\n",
            "Epoch 6/25\n",
            "6/6 [==============================] - 1s 86ms/step - loss: 0.3181 - accuracy: 0.8565\n",
            "Epoch 7/25\n",
            "6/6 [==============================] - 1s 103ms/step - loss: 0.2837 - accuracy: 0.8631\n",
            "Epoch 8/25\n",
            "6/6 [==============================] - 1s 94ms/step - loss: 0.2577 - accuracy: 0.8852\n",
            "Epoch 9/25\n",
            "6/6 [==============================] - 1s 90ms/step - loss: 0.2334 - accuracy: 0.9029\n",
            "Epoch 10/25\n",
            "6/6 [==============================] - 1s 84ms/step - loss: 0.2045 - accuracy: 0.9183\n",
            "Epoch 11/25\n",
            "6/6 [==============================] - 1s 88ms/step - loss: 0.1842 - accuracy: 0.9205\n",
            "Epoch 12/25\n",
            "6/6 [==============================] - 1s 84ms/step - loss: 0.1444 - accuracy: 0.9382\n",
            "Epoch 13/25\n",
            "6/6 [==============================] - 1s 136ms/step - loss: 0.1294 - accuracy: 0.9536\n",
            "Epoch 14/25\n",
            "6/6 [==============================] - 1s 168ms/step - loss: 0.1075 - accuracy: 0.9669\n",
            "Epoch 15/25\n",
            "6/6 [==============================] - 2s 268ms/step - loss: 0.0909 - accuracy: 0.9735\n",
            "Epoch 16/25\n",
            "6/6 [==============================] - 1s 144ms/step - loss: 0.0734 - accuracy: 0.9779\n",
            "Epoch 17/25\n",
            "6/6 [==============================] - 1s 145ms/step - loss: 0.0713 - accuracy: 0.9801\n",
            "Epoch 18/25\n",
            "6/6 [==============================] - 1s 106ms/step - loss: 0.0636 - accuracy: 0.9801\n",
            "Epoch 19/25\n",
            "6/6 [==============================] - 1s 105ms/step - loss: 0.0634 - accuracy: 0.9801\n",
            "Epoch 20/25\n",
            "6/6 [==============================] - 1s 101ms/step - loss: 0.0464 - accuracy: 0.9934\n",
            "Epoch 21/25\n",
            "6/6 [==============================] - 1s 109ms/step - loss: 0.0486 - accuracy: 0.9868\n",
            "Epoch 22/25\n",
            "6/6 [==============================] - 1s 103ms/step - loss: 0.0374 - accuracy: 0.9912\n",
            "Epoch 23/25\n",
            "6/6 [==============================] - 1s 108ms/step - loss: 0.0262 - accuracy: 1.0000\n",
            "Epoch 24/25\n",
            "6/6 [==============================] - 1s 103ms/step - loss: 0.0302 - accuracy: 0.9934\n",
            "Epoch 25/25\n",
            "6/6 [==============================] - 1s 92ms/step - loss: 0.0270 - accuracy: 0.9956\n",
            "5/5 [==============================] - 0s 10ms/step\n",
            "5/5 [==============================] - 0s 36ms/step\n",
            "5/5 [==============================] - 0s 14ms/step\n",
            "5/5 [==============================] - 0s 10ms/step\n",
            "5/5 [==============================] - 0s 46ms/step\n",
            "5/5 [==============================] - 0s 22ms/step\n",
            "Stacking with Random Forest - Accuracy: 0.7947019867549668\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### XGBoost"
      ],
      "metadata": {
        "id": "GqHwNTT3dqrk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to generate predictions for stacking\n",
        "def generate_predictions(model, X):\n",
        "    return model.predict(X).reshape(-1, 1)\n",
        "\n",
        "# Training the CNN models\n",
        "model_1 = create_cnn_model_1(input_shape)\n",
        "model_2 = create_cnn_model_2(input_shape)\n",
        "model_3 = create_cnn_model_3(input_shape)\n",
        "\n",
        "# Training and generating predictions\n",
        "model_1.fit(X_train, y_train, epochs=epochs, batch_size=batch_size)\n",
        "model_2.fit(X_train, y_train, epochs=epochs, batch_size=batch_size)\n",
        "model_3.fit(X_train, y_train, epochs=epochs, batch_size=batch_size)\n",
        "\n",
        "predictions_1 = generate_predictions(model_1, X_val)\n",
        "predictions_2 = generate_predictions(model_2, X_val)\n",
        "predictions_3 = generate_predictions(model_3, X_val)\n",
        "\n",
        "# Stacking the predictions\n",
        "stacked_predictions = np.hstack((predictions_1, predictions_2, predictions_3))\n",
        "\n",
        "# Training different meta-models on the stacked predictions\n",
        "meta_model_xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
        "meta_model_xgb.fit(stacked_predictions, y_val)\n",
        "\n",
        "# Evaluating the meta-model on the test set\n",
        "# First, getting predictions from the base models on the test set\n",
        "test_predictions_1 = generate_predictions(model_1, X_test)\n",
        "test_predictions_2 = generate_predictions(model_2, X_test)\n",
        "test_predictions_3 = generate_predictions(model_3, X_test)\n",
        "\n",
        "# Stacking the test set predictions\n",
        "stacked_test_predictions = np.hstack((test_predictions_1, test_predictions_2, test_predictions_3))\n",
        "\n",
        "# Making final predictions with the meta-model\n",
        "final_predictions_xgb = meta_model_xgb.predict(stacked_test_predictions)\n",
        "\n",
        "# Evaluating accuracy\n",
        "accuracy_xgb = accuracy_score(y_test, final_predictions_xgb)\n",
        "print(\"Stacking with XGBoost - Accuracy:\", accuracy_xgb)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NgXccTsyOPgl",
        "outputId": "78206a15-ae4c-4ccc-80d1-cc923fa346e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.10/dist-packages (2.0.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.11.3)\n",
            "Epoch 1/25\n",
            "6/6 [==============================] - 1s 60ms/step - loss: 0.7014 - accuracy: 0.7174\n",
            "Epoch 2/25\n",
            "6/6 [==============================] - 0s 55ms/step - loss: 0.4863 - accuracy: 0.7837\n",
            "Epoch 3/25\n",
            "6/6 [==============================] - 0s 57ms/step - loss: 0.3960 - accuracy: 0.8344\n",
            "Epoch 4/25\n",
            "6/6 [==============================] - 0s 53ms/step - loss: 0.3494 - accuracy: 0.8499\n",
            "Epoch 5/25\n",
            "6/6 [==============================] - 0s 53ms/step - loss: 0.3248 - accuracy: 0.8521\n",
            "Epoch 6/25\n",
            "6/6 [==============================] - 0s 57ms/step - loss: 0.3005 - accuracy: 0.8653\n",
            "Epoch 7/25\n",
            "6/6 [==============================] - 0s 53ms/step - loss: 0.2887 - accuracy: 0.8808\n",
            "Epoch 8/25\n",
            "6/6 [==============================] - 0s 65ms/step - loss: 0.2597 - accuracy: 0.8808\n",
            "Epoch 9/25\n",
            "6/6 [==============================] - 0s 69ms/step - loss: 0.2312 - accuracy: 0.9051\n",
            "Epoch 10/25\n",
            "6/6 [==============================] - 1s 96ms/step - loss: 0.2026 - accuracy: 0.9272\n",
            "Epoch 11/25\n",
            "6/6 [==============================] - 1s 101ms/step - loss: 0.1920 - accuracy: 0.9161\n",
            "Epoch 12/25\n",
            "6/6 [==============================] - 1s 91ms/step - loss: 0.1688 - accuracy: 0.9227\n",
            "Epoch 13/25\n",
            "6/6 [==============================] - 1s 87ms/step - loss: 0.1462 - accuracy: 0.9448\n",
            "Epoch 14/25\n",
            "6/6 [==============================] - 1s 89ms/step - loss: 0.1257 - accuracy: 0.9735\n",
            "Epoch 15/25\n",
            "6/6 [==============================] - 1s 92ms/step - loss: 0.1130 - accuracy: 0.9603\n",
            "Epoch 16/25\n",
            "6/6 [==============================] - 1s 105ms/step - loss: 0.1111 - accuracy: 0.9558\n",
            "Epoch 17/25\n",
            "6/6 [==============================] - 1s 90ms/step - loss: 0.0928 - accuracy: 0.9868\n",
            "Epoch 18/25\n",
            "6/6 [==============================] - 1s 89ms/step - loss: 0.0892 - accuracy: 0.9713\n",
            "Epoch 19/25\n",
            "6/6 [==============================] - 0s 59ms/step - loss: 0.0765 - accuracy: 0.9779\n",
            "Epoch 20/25\n",
            "6/6 [==============================] - 0s 63ms/step - loss: 0.0684 - accuracy: 0.9868\n",
            "Epoch 21/25\n",
            "6/6 [==============================] - 0s 69ms/step - loss: 0.0598 - accuracy: 0.9823\n",
            "Epoch 22/25\n",
            "6/6 [==============================] - 0s 54ms/step - loss: 0.0525 - accuracy: 0.9868\n",
            "Epoch 23/25\n",
            "6/6 [==============================] - 0s 56ms/step - loss: 0.0398 - accuracy: 0.9978\n",
            "Epoch 24/25\n",
            "6/6 [==============================] - 0s 55ms/step - loss: 0.0456 - accuracy: 0.9868\n",
            "Epoch 25/25\n",
            "6/6 [==============================] - 0s 73ms/step - loss: 0.0397 - accuracy: 0.9934\n",
            "Epoch 1/25\n",
            "6/6 [==============================] - 4s 408ms/step - loss: 3.5267 - accuracy: 0.7174\n",
            "Epoch 2/25\n",
            "6/6 [==============================] - 2s 364ms/step - loss: 2.5173 - accuracy: 0.7748\n",
            "Epoch 3/25\n",
            "6/6 [==============================] - 2s 401ms/step - loss: 1.6011 - accuracy: 0.7638\n",
            "Epoch 4/25\n",
            "6/6 [==============================] - 3s 569ms/step - loss: 0.9164 - accuracy: 0.8212\n",
            "Epoch 5/25\n",
            "6/6 [==============================] - 3s 573ms/step - loss: 0.5922 - accuracy: 0.8698\n",
            "Epoch 6/25\n",
            "6/6 [==============================] - 3s 443ms/step - loss: 0.4429 - accuracy: 0.8830\n",
            "Epoch 7/25\n",
            "6/6 [==============================] - 3s 449ms/step - loss: 0.3180 - accuracy: 0.8698\n",
            "Epoch 8/25\n",
            "6/6 [==============================] - 3s 456ms/step - loss: 0.2803 - accuracy: 0.8808\n",
            "Epoch 9/25\n",
            "6/6 [==============================] - 3s 542ms/step - loss: 0.2144 - accuracy: 0.9073\n",
            "Epoch 10/25\n",
            "6/6 [==============================] - 4s 586ms/step - loss: 0.1455 - accuracy: 0.9316\n",
            "Epoch 11/25\n",
            "6/6 [==============================] - 2s 346ms/step - loss: 0.1240 - accuracy: 0.9625\n",
            "Epoch 12/25\n",
            "6/6 [==============================] - 2s 351ms/step - loss: 0.1292 - accuracy: 0.9603\n",
            "Epoch 13/25\n",
            "6/6 [==============================] - 3s 426ms/step - loss: 0.1094 - accuracy: 0.9536\n",
            "Epoch 14/25\n",
            "6/6 [==============================] - 2s 392ms/step - loss: 0.0725 - accuracy: 0.9757\n",
            "Epoch 15/25\n",
            "6/6 [==============================] - 3s 563ms/step - loss: 0.0934 - accuracy: 0.9581\n",
            "Epoch 16/25\n",
            "6/6 [==============================] - 3s 519ms/step - loss: 0.0612 - accuracy: 0.9801\n",
            "Epoch 17/25\n",
            "6/6 [==============================] - 2s 398ms/step - loss: 0.0658 - accuracy: 0.9757\n",
            "Epoch 18/25\n",
            "6/6 [==============================] - 2s 378ms/step - loss: 0.0475 - accuracy: 0.9934\n",
            "Epoch 19/25\n",
            "6/6 [==============================] - 3s 420ms/step - loss: 0.0517 - accuracy: 0.9890\n",
            "Epoch 20/25\n",
            "6/6 [==============================] - 3s 501ms/step - loss: 0.0339 - accuracy: 0.9934\n",
            "Epoch 21/25\n",
            "6/6 [==============================] - 3s 549ms/step - loss: 0.0352 - accuracy: 0.9978\n",
            "Epoch 22/25\n",
            "6/6 [==============================] - 2s 373ms/step - loss: 0.0187 - accuracy: 1.0000\n",
            "Epoch 23/25\n",
            "6/6 [==============================] - 3s 485ms/step - loss: 0.0245 - accuracy: 0.9978\n",
            "Epoch 24/25\n",
            "6/6 [==============================] - 2s 397ms/step - loss: 0.0179 - accuracy: 0.9978\n",
            "Epoch 25/25\n",
            "6/6 [==============================] - 2s 421ms/step - loss: 0.0261 - accuracy: 0.9934\n",
            "Epoch 1/25\n",
            "6/6 [==============================] - 2s 153ms/step - loss: 0.6204 - accuracy: 0.6645\n",
            "Epoch 2/25\n",
            "6/6 [==============================] - 1s 155ms/step - loss: 0.4751 - accuracy: 0.8278\n",
            "Epoch 3/25\n",
            "6/6 [==============================] - 1s 105ms/step - loss: 0.3916 - accuracy: 0.8234\n",
            "Epoch 4/25\n",
            "6/6 [==============================] - 1s 102ms/step - loss: 0.3407 - accuracy: 0.8587\n",
            "Epoch 5/25\n",
            "6/6 [==============================] - 1s 98ms/step - loss: 0.2974 - accuracy: 0.8565\n",
            "Epoch 6/25\n",
            "6/6 [==============================] - 1s 101ms/step - loss: 0.2721 - accuracy: 0.8808\n",
            "Epoch 7/25\n",
            "6/6 [==============================] - 1s 99ms/step - loss: 0.2308 - accuracy: 0.9117\n",
            "Epoch 8/25\n",
            "6/6 [==============================] - 1s 100ms/step - loss: 0.1958 - accuracy: 0.9095\n",
            "Epoch 9/25\n",
            "6/6 [==============================] - 1s 89ms/step - loss: 0.1579 - accuracy: 0.9360\n",
            "Epoch 10/25\n",
            "6/6 [==============================] - 1s 86ms/step - loss: 0.1444 - accuracy: 0.9426\n",
            "Epoch 11/25\n",
            "6/6 [==============================] - 1s 92ms/step - loss: 0.1120 - accuracy: 0.9581\n",
            "Epoch 12/25\n",
            "6/6 [==============================] - 1s 97ms/step - loss: 0.0800 - accuracy: 0.9801\n",
            "Epoch 13/25\n",
            "6/6 [==============================] - 1s 99ms/step - loss: 0.0683 - accuracy: 0.9823\n",
            "Epoch 14/25\n",
            "6/6 [==============================] - 1s 97ms/step - loss: 0.0492 - accuracy: 0.9934\n",
            "Epoch 15/25\n",
            "6/6 [==============================] - 1s 86ms/step - loss: 0.0394 - accuracy: 0.9934\n",
            "Epoch 16/25\n",
            "6/6 [==============================] - 1s 87ms/step - loss: 0.0416 - accuracy: 0.9934\n",
            "Epoch 17/25\n",
            "6/6 [==============================] - 1s 100ms/step - loss: 0.0295 - accuracy: 1.0000\n",
            "Epoch 18/25\n",
            "6/6 [==============================] - 1s 95ms/step - loss: 0.0263 - accuracy: 0.9978\n",
            "Epoch 19/25\n",
            "6/6 [==============================] - 1s 100ms/step - loss: 0.0204 - accuracy: 0.9956\n",
            "Epoch 20/25\n",
            "6/6 [==============================] - 1s 156ms/step - loss: 0.0152 - accuracy: 1.0000\n",
            "Epoch 21/25\n",
            "6/6 [==============================] - 1s 153ms/step - loss: 0.0143 - accuracy: 1.0000\n",
            "Epoch 22/25\n",
            "6/6 [==============================] - 1s 139ms/step - loss: 0.0143 - accuracy: 0.9956\n",
            "Epoch 23/25\n",
            "6/6 [==============================] - 1s 145ms/step - loss: 0.0118 - accuracy: 1.0000\n",
            "Epoch 24/25\n",
            "6/6 [==============================] - 1s 141ms/step - loss: 0.0175 - accuracy: 0.9956\n",
            "Epoch 25/25\n",
            "6/6 [==============================] - 1s 141ms/step - loss: 0.0098 - accuracy: 1.0000\n",
            "5/5 [==============================] - 0s 10ms/step\n",
            "5/5 [==============================] - 0s 34ms/step\n",
            "5/5 [==============================] - 0s 12ms/step\n",
            "5/5 [==============================] - 0s 8ms/step\n",
            "5/5 [==============================] - 0s 32ms/step\n",
            "5/5 [==============================] - 0s 12ms/step\n",
            "Stacking with XGBoost - Accuracy: 0.8013245033112583\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### SVM"
      ],
      "metadata": {
        "id": "XQLuRRNGdvEb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to generate predictions for stacking\n",
        "def generate_predictions(model, X):\n",
        "    return model.predict(X).reshape(-1, 1)\n",
        "\n",
        "# Training the CNN models\n",
        "model_1 = create_cnn_model_1(input_shape)\n",
        "model_2 = create_cnn_model_2(input_shape)\n",
        "model_3 = create_cnn_model_3(input_shape)\n",
        "\n",
        "# Training and generating predictions\n",
        "model_1.fit(X_train, y_train, epochs=epochs, batch_size=batch_size)\n",
        "model_2.fit(X_train, y_train, epochs=epochs, batch_size=batch_size)\n",
        "model_3.fit(X_train, y_train, epochs=epochs, batch_size=batch_size)\n",
        "\n",
        "predictions_1 = generate_predictions(model_1, X_val)\n",
        "predictions_2 = generate_predictions(model_2, X_val)\n",
        "predictions_3 = generate_predictions(model_3, X_val)\n",
        "\n",
        "# Stacking the predictions\n",
        "stacked_predictions = np.hstack((predictions_1, predictions_2, predictions_3))\n",
        "\n",
        "# Training different meta-models on the stacked predictions\n",
        "\n",
        "meta_model_svm = SVC(probability=True)\n",
        "meta_model_svm.fit(stacked_predictions, y_val)\n",
        "\n",
        "# Evaluate the meta-model on the test set\n",
        "# First, getting predictions from the base models on the test set\n",
        "test_predictions_1 = generate_predictions(model_1, X_test)\n",
        "test_predictions_2 = generate_predictions(model_2, X_test)\n",
        "test_predictions_3 = generate_predictions(model_3, X_test)\n",
        "\n",
        "# Stacking the test set predictions\n",
        "stacked_test_predictions = np.hstack((test_predictions_1, test_predictions_2, test_predictions_3))\n",
        "\n",
        "# Making final predictions with the meta-model\n",
        "final_predictions_svm = meta_model_svm.predict(stacked_test_predictions)\n",
        "\n",
        "# Evaluating accuracy\n",
        "accuracy_svm = accuracy_score(y_test, final_predictions_svm)\n",
        "print(\"Stacking with SVM - Accuracy:\", accuracy_svm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8z1BoqlrPzN8",
        "outputId": "e4327cd5-5fe3-4c42-b14d-e5de0981c82f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "6/6 [==============================] - 2s 70ms/step - loss: 0.6582 - accuracy: 0.7329\n",
            "Epoch 2/25\n",
            "6/6 [==============================] - 0s 62ms/step - loss: 0.4937 - accuracy: 0.8079\n",
            "Epoch 3/25\n",
            "6/6 [==============================] - 0s 64ms/step - loss: 0.4079 - accuracy: 0.8278\n",
            "Epoch 4/25\n",
            "6/6 [==============================] - 0s 64ms/step - loss: 0.3474 - accuracy: 0.8521\n",
            "Epoch 5/25\n",
            "6/6 [==============================] - 0s 61ms/step - loss: 0.3181 - accuracy: 0.8587\n",
            "Epoch 6/25\n",
            "6/6 [==============================] - 0s 62ms/step - loss: 0.3021 - accuracy: 0.8565\n",
            "Epoch 7/25\n",
            "6/6 [==============================] - 0s 65ms/step - loss: 0.2540 - accuracy: 0.8985\n",
            "Epoch 8/25\n",
            "6/6 [==============================] - 1s 89ms/step - loss: 0.2449 - accuracy: 0.9007\n",
            "Epoch 9/25\n",
            "6/6 [==============================] - 1s 102ms/step - loss: 0.2290 - accuracy: 0.9007\n",
            "Epoch 10/25\n",
            "6/6 [==============================] - 1s 101ms/step - loss: 0.2001 - accuracy: 0.9183\n",
            "Epoch 11/25\n",
            "6/6 [==============================] - 1s 95ms/step - loss: 0.1761 - accuracy: 0.9272\n",
            "Epoch 12/25\n",
            "6/6 [==============================] - 1s 98ms/step - loss: 0.1528 - accuracy: 0.9426\n",
            "Epoch 13/25\n",
            "6/6 [==============================] - 1s 84ms/step - loss: 0.1402 - accuracy: 0.9470\n",
            "Epoch 14/25\n",
            "6/6 [==============================] - 1s 87ms/step - loss: 0.1228 - accuracy: 0.9558\n",
            "Epoch 15/25\n",
            "6/6 [==============================] - 0s 77ms/step - loss: 0.1132 - accuracy: 0.9581\n",
            "Epoch 16/25\n",
            "6/6 [==============================] - 0s 80ms/step - loss: 0.1006 - accuracy: 0.9669\n",
            "Epoch 17/25\n",
            "6/6 [==============================] - 0s 54ms/step - loss: 0.0826 - accuracy: 0.9845\n",
            "Epoch 18/25\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 0.0795 - accuracy: 0.9801\n",
            "Epoch 19/25\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 0.0667 - accuracy: 0.9845\n",
            "Epoch 20/25\n",
            "6/6 [==============================] - 0s 61ms/step - loss: 0.0681 - accuracy: 0.9823\n",
            "Epoch 21/25\n",
            "6/6 [==============================] - 0s 62ms/step - loss: 0.0561 - accuracy: 0.9890\n",
            "Epoch 22/25\n",
            "6/6 [==============================] - 0s 64ms/step - loss: 0.0483 - accuracy: 0.9978\n",
            "Epoch 23/25\n",
            "6/6 [==============================] - 0s 62ms/step - loss: 0.0445 - accuracy: 0.9956\n",
            "Epoch 24/25\n",
            "6/6 [==============================] - 0s 65ms/step - loss: 0.0402 - accuracy: 0.9912\n",
            "Epoch 25/25\n",
            "6/6 [==============================] - 0s 61ms/step - loss: 0.0291 - accuracy: 1.0000\n",
            "Epoch 1/25\n",
            "6/6 [==============================] - 4s 416ms/step - loss: 4.6879 - accuracy: 0.6799\n",
            "Epoch 2/25\n",
            "6/6 [==============================] - 3s 439ms/step - loss: 2.3190 - accuracy: 0.8057\n",
            "Epoch 3/25\n",
            "6/6 [==============================] - 2s 420ms/step - loss: 1.4583 - accuracy: 0.8057\n",
            "Epoch 4/25\n",
            "6/6 [==============================] - 3s 593ms/step - loss: 1.1668 - accuracy: 0.7704\n",
            "Epoch 5/25\n",
            "6/6 [==============================] - 3s 451ms/step - loss: 0.5628 - accuracy: 0.8565\n",
            "Epoch 6/25\n",
            "6/6 [==============================] - 2s 415ms/step - loss: 0.5384 - accuracy: 0.8366\n",
            "Epoch 7/25\n",
            "6/6 [==============================] - 3s 449ms/step - loss: 0.3455 - accuracy: 0.8720\n",
            "Epoch 8/25\n",
            "6/6 [==============================] - 2s 397ms/step - loss: 0.3230 - accuracy: 0.8587\n",
            "Epoch 9/25\n",
            "6/6 [==============================] - 3s 449ms/step - loss: 0.2137 - accuracy: 0.9161\n",
            "Epoch 10/25\n",
            "6/6 [==============================] - 4s 609ms/step - loss: 0.2157 - accuracy: 0.9073\n",
            "Epoch 11/25\n",
            "6/6 [==============================] - 2s 354ms/step - loss: 0.1832 - accuracy: 0.9183\n",
            "Epoch 12/25\n",
            "6/6 [==============================] - 2s 394ms/step - loss: 0.1645 - accuracy: 0.9448\n",
            "Epoch 13/25\n",
            "6/6 [==============================] - 3s 442ms/step - loss: 0.1805 - accuracy: 0.9338\n",
            "Epoch 14/25\n",
            "6/6 [==============================] - 2s 397ms/step - loss: 0.1408 - accuracy: 0.9382\n",
            "Epoch 15/25\n",
            "6/6 [==============================] - 4s 618ms/step - loss: 0.0890 - accuracy: 0.9713\n",
            "Epoch 16/25\n",
            "6/6 [==============================] - 3s 480ms/step - loss: 0.1027 - accuracy: 0.9647\n",
            "Epoch 17/25\n",
            "6/6 [==============================] - 3s 435ms/step - loss: 0.1129 - accuracy: 0.9757\n",
            "Epoch 18/25\n",
            "6/6 [==============================] - 2s 419ms/step - loss: 0.0821 - accuracy: 0.9757\n",
            "Epoch 19/25\n",
            "6/6 [==============================] - 2s 409ms/step - loss: 0.0726 - accuracy: 0.9779\n",
            "Epoch 20/25\n",
            "6/6 [==============================] - 4s 691ms/step - loss: 0.0710 - accuracy: 0.9801\n",
            "Epoch 21/25\n",
            "6/6 [==============================] - 3s 463ms/step - loss: 0.0647 - accuracy: 0.9823\n",
            "Epoch 22/25\n",
            "6/6 [==============================] - 2s 384ms/step - loss: 0.0536 - accuracy: 0.9801\n",
            "Epoch 23/25\n",
            "6/6 [==============================] - 2s 340ms/step - loss: 0.0628 - accuracy: 0.9801\n",
            "Epoch 24/25\n",
            "6/6 [==============================] - 2s 375ms/step - loss: 0.0432 - accuracy: 0.9934\n",
            "Epoch 25/25\n",
            "6/6 [==============================] - 2s 362ms/step - loss: 0.0369 - accuracy: 0.9890\n",
            "Epoch 1/25\n",
            "6/6 [==============================] - 2s 94ms/step - loss: 0.7317 - accuracy: 0.6556\n",
            "Epoch 2/25\n",
            "6/6 [==============================] - 1s 85ms/step - loss: 0.5189 - accuracy: 0.7859\n",
            "Epoch 3/25\n",
            "6/6 [==============================] - 1s 98ms/step - loss: 0.4292 - accuracy: 0.8035\n",
            "Epoch 4/25\n",
            "6/6 [==============================] - 1s 101ms/step - loss: 0.4120 - accuracy: 0.8212\n",
            "Epoch 5/25\n",
            "6/6 [==============================] - 1s 87ms/step - loss: 0.3676 - accuracy: 0.8521\n",
            "Epoch 6/25\n",
            "6/6 [==============================] - 1s 85ms/step - loss: 0.3293 - accuracy: 0.8565\n",
            "Epoch 7/25\n",
            "6/6 [==============================] - 1s 100ms/step - loss: 0.3093 - accuracy: 0.8587\n",
            "Epoch 8/25\n",
            "6/6 [==============================] - 1s 97ms/step - loss: 0.2696 - accuracy: 0.8874\n",
            "Epoch 9/25\n",
            "6/6 [==============================] - 1s 85ms/step - loss: 0.2552 - accuracy: 0.8918\n",
            "Epoch 10/25\n",
            "6/6 [==============================] - 1s 86ms/step - loss: 0.2165 - accuracy: 0.9073\n",
            "Epoch 11/25\n",
            "6/6 [==============================] - 1s 84ms/step - loss: 0.2071 - accuracy: 0.9161\n",
            "Epoch 12/25\n",
            "6/6 [==============================] - 1s 83ms/step - loss: 0.1596 - accuracy: 0.9448\n",
            "Epoch 13/25\n",
            "6/6 [==============================] - 1s 86ms/step - loss: 0.1333 - accuracy: 0.9536\n",
            "Epoch 14/25\n",
            "6/6 [==============================] - 1s 85ms/step - loss: 0.1296 - accuracy: 0.9581\n",
            "Epoch 15/25\n",
            "6/6 [==============================] - 1s 86ms/step - loss: 0.1128 - accuracy: 0.9735\n",
            "Epoch 16/25\n",
            "6/6 [==============================] - 1s 84ms/step - loss: 0.1040 - accuracy: 0.9558\n",
            "Epoch 17/25\n",
            "6/6 [==============================] - 1s 85ms/step - loss: 0.0834 - accuracy: 0.9713\n",
            "Epoch 18/25\n",
            "6/6 [==============================] - 1s 98ms/step - loss: 0.0744 - accuracy: 0.9757\n",
            "Epoch 19/25\n",
            "6/6 [==============================] - 1s 152ms/step - loss: 0.0610 - accuracy: 0.9868\n",
            "Epoch 20/25\n",
            "6/6 [==============================] - 1s 165ms/step - loss: 0.0655 - accuracy: 0.9735\n",
            "Epoch 21/25\n",
            "6/6 [==============================] - 1s 161ms/step - loss: 0.0489 - accuracy: 0.9845\n",
            "Epoch 22/25\n",
            "6/6 [==============================] - 1s 161ms/step - loss: 0.0366 - accuracy: 0.9956\n",
            "Epoch 23/25\n",
            "6/6 [==============================] - 1s 140ms/step - loss: 0.0305 - accuracy: 0.9978\n",
            "Epoch 24/25\n",
            "6/6 [==============================] - 1s 86ms/step - loss: 0.0390 - accuracy: 0.9868\n",
            "Epoch 25/25\n",
            "6/6 [==============================] - 1s 88ms/step - loss: 0.0298 - accuracy: 0.9956\n",
            "5/5 [==============================] - 0s 10ms/step\n",
            "5/5 [==============================] - 0s 40ms/step\n",
            "5/5 [==============================] - 0s 14ms/step\n",
            "5/5 [==============================] - 0s 10ms/step\n",
            "5/5 [==============================] - 0s 36ms/step\n",
            "5/5 [==============================] - 0s 14ms/step\n",
            "Stacking with SVM - Accuracy: 0.8278145695364238\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### CNN (As meta model)"
      ],
      "metadata": {
        "id": "u-Mc0S-pdzf1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to generate predictions for stacking\n",
        "def generate_predictions(model, X):\n",
        "    return model.predict(X).reshape(-1, 1)\n",
        "\n",
        "# Training the CNN models\n",
        "model_1 = create_cnn_model_1(input_shape)\n",
        "model_2 = create_cnn_model_2(input_shape)\n",
        "model_3 = create_cnn_model_3(input_shape)\n",
        "\n",
        "# Training and generating predictions\n",
        "model_1.fit(X_train, y_train, epochs=epochs, batch_size=batch_size)\n",
        "model_2.fit(X_train, y_train, epochs=epochs, batch_size=batch_size)\n",
        "model_3.fit(X_train, y_train, epochs=epochs, batch_size=batch_size)\n",
        "\n",
        "predictions_1 = generate_predictions(model_1, X_val)\n",
        "predictions_2 = generate_predictions(model_2, X_val)\n",
        "predictions_3 = generate_predictions(model_3, X_val)\n",
        "\n",
        "test_predictions_1 = generate_predictions(model_1, X_test)\n",
        "test_predictions_2 = generate_predictions(model_2, X_test)\n",
        "test_predictions_3 = generate_predictions(model_3, X_test)\n",
        "\n",
        "# Stacking the test set predictions\n",
        "stacked_test_predictions = np.hstack((test_predictions_1, test_predictions_2, test_predictions_3))\n",
        "\n",
        "# Stacking the predictions\n",
        "stacked_predictions = np.hstack((predictions_1, predictions_2, predictions_3))\n",
        "\n",
        "# Reshaping stacked predictions for CNN input\n",
        "stacked_predictions_cnn = np.expand_dims(stacked_predictions, axis=2)  # Add an extra dimension\n",
        "\n",
        "# Similarly, reshaping the test set predictions\n",
        "stacked_test_predictions_cnn = np.expand_dims(stacked_test_predictions, axis=2)\n",
        "\n",
        "def create_cnn_meta_model(input_shape):\n",
        "    model = Sequential([\n",
        "        Conv1D(filters=32, kernel_size=1, activation='relu', input_shape=input_shape),\n",
        "        MaxPooling1D(pool_size=2),\n",
        "        Flatten(),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Creating the CNN meta-model\n",
        "input_shape_meta = (stacked_predictions_cnn.shape[1], stacked_predictions_cnn.shape[2])\n",
        "meta_model_cnn = create_cnn_meta_model(input_shape_meta)\n",
        "\n",
        "# Training the CNN meta-model\n",
        "meta_model_cnn.fit(stacked_predictions_cnn, y_val, epochs=10, batch_size=32)\n",
        "\n",
        "# Making final predictions with the meta-model\n",
        "final_predictions_cnn = meta_model_cnn.predict(stacked_test_predictions_cnn)\n",
        "\n",
        "# Threshold the predictions\n",
        "final_predictions_cnn = (final_predictions_cnn > 0.5).astype(int).flatten()\n",
        "\n",
        "# Evaluating accuracy\n",
        "accuracy_cnn = accuracy_score(y_test, final_predictions_cnn)\n",
        "print(\"Stacking with CNN Meta-Model - Accuracy:\", accuracy_cnn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JvdhRFh-RAZa",
        "outputId": "1c78a484-2c9f-47ff-9ff9-5a07409f345d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "6/6 [==============================] - 2s 97ms/step - loss: 0.6441 - accuracy: 0.7020\n",
            "Epoch 2/25\n",
            "6/6 [==============================] - 1s 98ms/step - loss: 0.4819 - accuracy: 0.7903\n",
            "Epoch 3/25\n",
            "6/6 [==============================] - 1s 99ms/step - loss: 0.3917 - accuracy: 0.8146\n",
            "Epoch 4/25\n",
            "6/6 [==============================] - 1s 90ms/step - loss: 0.3546 - accuracy: 0.8631\n",
            "Epoch 5/25\n",
            "6/6 [==============================] - 1s 86ms/step - loss: 0.3233 - accuracy: 0.8521\n",
            "Epoch 6/25\n",
            "6/6 [==============================] - 1s 98ms/step - loss: 0.2932 - accuracy: 0.8653\n",
            "Epoch 7/25\n",
            "6/6 [==============================] - 1s 96ms/step - loss: 0.2674 - accuracy: 0.8764\n",
            "Epoch 8/25\n",
            "6/6 [==============================] - 0s 67ms/step - loss: 0.2442 - accuracy: 0.8808\n",
            "Epoch 9/25\n",
            "6/6 [==============================] - 0s 64ms/step - loss: 0.2226 - accuracy: 0.9095\n",
            "Epoch 10/25\n",
            "6/6 [==============================] - 0s 62ms/step - loss: 0.1975 - accuracy: 0.9272\n",
            "Epoch 11/25\n",
            "6/6 [==============================] - 0s 68ms/step - loss: 0.1726 - accuracy: 0.9360\n",
            "Epoch 12/25\n",
            "6/6 [==============================] - 0s 57ms/step - loss: 0.1658 - accuracy: 0.9536\n",
            "Epoch 13/25\n",
            "6/6 [==============================] - 0s 52ms/step - loss: 0.1460 - accuracy: 0.9536\n",
            "Epoch 14/25\n",
            "6/6 [==============================] - 0s 53ms/step - loss: 0.1193 - accuracy: 0.9625\n",
            "Epoch 15/25\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 0.1054 - accuracy: 0.9647\n",
            "Epoch 16/25\n",
            "6/6 [==============================] - 0s 52ms/step - loss: 0.0924 - accuracy: 0.9757\n",
            "Epoch 17/25\n",
            "6/6 [==============================] - 0s 52ms/step - loss: 0.0963 - accuracy: 0.9669\n",
            "Epoch 18/25\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.0899 - accuracy: 0.9735\n",
            "Epoch 19/25\n",
            "6/6 [==============================] - 0s 53ms/step - loss: 0.0673 - accuracy: 0.9890\n",
            "Epoch 20/25\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.0617 - accuracy: 0.9845\n",
            "Epoch 21/25\n",
            "6/6 [==============================] - 0s 52ms/step - loss: 0.0562 - accuracy: 0.9890\n",
            "Epoch 22/25\n",
            "6/6 [==============================] - 0s 54ms/step - loss: 0.0476 - accuracy: 0.9890\n",
            "Epoch 23/25\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 0.0534 - accuracy: 0.9868\n",
            "Epoch 24/25\n",
            "6/6 [==============================] - 0s 54ms/step - loss: 0.0370 - accuracy: 0.9934\n",
            "Epoch 25/25\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 0.0389 - accuracy: 0.9890\n",
            "Epoch 1/25\n",
            "6/6 [==============================] - 4s 410ms/step - loss: 5.1074 - accuracy: 0.6380\n",
            "Epoch 2/25\n",
            "6/6 [==============================] - 4s 665ms/step - loss: 1.3897 - accuracy: 0.8057\n",
            "Epoch 3/25\n",
            "6/6 [==============================] - 3s 420ms/step - loss: 0.7579 - accuracy: 0.7130\n",
            "Epoch 4/25\n",
            "6/6 [==============================] - 3s 430ms/step - loss: 0.4058 - accuracy: 0.8212\n",
            "Epoch 5/25\n",
            "6/6 [==============================] - 2s 363ms/step - loss: 0.3676 - accuracy: 0.8190\n",
            "Epoch 6/25\n",
            "6/6 [==============================] - 2s 399ms/step - loss: 0.3537 - accuracy: 0.8477\n",
            "Epoch 7/25\n",
            "6/6 [==============================] - 4s 627ms/step - loss: 0.3410 - accuracy: 0.8587\n",
            "Epoch 8/25\n",
            "6/6 [==============================] - 3s 520ms/step - loss: 0.3228 - accuracy: 0.8344\n",
            "Epoch 9/25\n",
            "6/6 [==============================] - 3s 427ms/step - loss: 0.2836 - accuracy: 0.8499\n",
            "Epoch 10/25\n",
            "6/6 [==============================] - 2s 383ms/step - loss: 0.2563 - accuracy: 0.8852\n",
            "Epoch 11/25\n",
            "6/6 [==============================] - 2s 385ms/step - loss: 0.2564 - accuracy: 0.8940\n",
            "Epoch 12/25\n",
            "6/6 [==============================] - 3s 430ms/step - loss: 0.2370 - accuracy: 0.8830\n",
            "Epoch 13/25\n",
            "6/6 [==============================] - 4s 595ms/step - loss: 0.2182 - accuracy: 0.9051\n",
            "Epoch 14/25\n",
            "6/6 [==============================] - 3s 426ms/step - loss: 0.1999 - accuracy: 0.9205\n",
            "Epoch 15/25\n",
            "6/6 [==============================] - 3s 417ms/step - loss: 0.1774 - accuracy: 0.9205\n",
            "Epoch 16/25\n",
            "6/6 [==============================] - 3s 418ms/step - loss: 0.1801 - accuracy: 0.9249\n",
            "Epoch 17/25\n",
            "6/6 [==============================] - 3s 418ms/step - loss: 0.1914 - accuracy: 0.9382\n",
            "Epoch 18/25\n",
            "6/6 [==============================] - 4s 623ms/step - loss: 0.1626 - accuracy: 0.9272\n",
            "Epoch 19/25\n",
            "6/6 [==============================] - 3s 431ms/step - loss: 0.1564 - accuracy: 0.9360\n",
            "Epoch 20/25\n",
            "6/6 [==============================] - 2s 410ms/step - loss: 0.1490 - accuracy: 0.9426\n",
            "Epoch 21/25\n",
            "6/6 [==============================] - 2s 368ms/step - loss: 0.1271 - accuracy: 0.9603\n",
            "Epoch 22/25\n",
            "6/6 [==============================] - 3s 419ms/step - loss: 0.1027 - accuracy: 0.9735\n",
            "Epoch 23/25\n",
            "6/6 [==============================] - 3s 441ms/step - loss: 0.1137 - accuracy: 0.9691\n",
            "Epoch 24/25\n",
            "6/6 [==============================] - 3s 561ms/step - loss: 0.0909 - accuracy: 0.9735\n",
            "Epoch 25/25\n",
            "6/6 [==============================] - 2s 368ms/step - loss: 0.1072 - accuracy: 0.9558\n",
            "Epoch 1/25\n",
            "6/6 [==============================] - 2s 109ms/step - loss: 0.6594 - accuracy: 0.6645\n",
            "Epoch 2/25\n",
            "6/6 [==============================] - 1s 96ms/step - loss: 0.4585 - accuracy: 0.8035\n",
            "Epoch 3/25\n",
            "6/6 [==============================] - 1s 99ms/step - loss: 0.3979 - accuracy: 0.8300\n",
            "Epoch 4/25\n",
            "6/6 [==============================] - 1s 96ms/step - loss: 0.3489 - accuracy: 0.8521\n",
            "Epoch 5/25\n",
            "6/6 [==============================] - 1s 95ms/step - loss: 0.3240 - accuracy: 0.8455\n",
            "Epoch 6/25\n",
            "6/6 [==============================] - 1s 97ms/step - loss: 0.2765 - accuracy: 0.8808\n",
            "Epoch 7/25\n",
            "6/6 [==============================] - 1s 95ms/step - loss: 0.2520 - accuracy: 0.8808\n",
            "Epoch 8/25\n",
            "6/6 [==============================] - 1s 98ms/step - loss: 0.2237 - accuracy: 0.9073\n",
            "Epoch 9/25\n",
            "6/6 [==============================] - 1s 92ms/step - loss: 0.1944 - accuracy: 0.9095\n",
            "Epoch 10/25\n",
            "6/6 [==============================] - 1s 85ms/step - loss: 0.1844 - accuracy: 0.9316\n",
            "Epoch 11/25\n",
            "6/6 [==============================] - 1s 100ms/step - loss: 0.1329 - accuracy: 0.9426\n",
            "Epoch 12/25\n",
            "6/6 [==============================] - 1s 156ms/step - loss: 0.1047 - accuracy: 0.9713\n",
            "Epoch 13/25\n",
            "6/6 [==============================] - 1s 156ms/step - loss: 0.0876 - accuracy: 0.9669\n",
            "Epoch 14/25\n",
            "6/6 [==============================] - 1s 159ms/step - loss: 0.0804 - accuracy: 0.9823\n",
            "Epoch 15/25\n",
            "6/6 [==============================] - 1s 155ms/step - loss: 0.0550 - accuracy: 0.9868\n",
            "Epoch 16/25\n",
            "6/6 [==============================] - 1s 130ms/step - loss: 0.0481 - accuracy: 0.9823\n",
            "Epoch 17/25\n",
            "6/6 [==============================] - 1s 97ms/step - loss: 0.0445 - accuracy: 0.9934\n",
            "Epoch 18/25\n",
            "6/6 [==============================] - 1s 95ms/step - loss: 0.0363 - accuracy: 0.9956\n",
            "Epoch 19/25\n",
            "6/6 [==============================] - 1s 85ms/step - loss: 0.0364 - accuracy: 0.9956\n",
            "Epoch 20/25\n",
            "6/6 [==============================] - 1s 82ms/step - loss: 0.0283 - accuracy: 0.9956\n",
            "Epoch 21/25\n",
            "6/6 [==============================] - 1s 99ms/step - loss: 0.0222 - accuracy: 0.9934\n",
            "Epoch 22/25\n",
            "6/6 [==============================] - 1s 96ms/step - loss: 0.0198 - accuracy: 0.9956\n",
            "Epoch 23/25\n",
            "6/6 [==============================] - 1s 99ms/step - loss: 0.0207 - accuracy: 0.9956\n",
            "Epoch 24/25\n",
            "6/6 [==============================] - 1s 91ms/step - loss: 0.0148 - accuracy: 0.9978\n",
            "Epoch 25/25\n",
            "6/6 [==============================] - 1s 86ms/step - loss: 0.0242 - accuracy: 0.9912\n",
            "5/5 [==============================] - 0s 9ms/step\n",
            "5/5 [==============================] - 0s 33ms/step\n",
            "5/5 [==============================] - 0s 11ms/step\n",
            "5/5 [==============================] - 0s 8ms/step\n",
            "5/5 [==============================] - 0s 30ms/step\n",
            "5/5 [==============================] - 0s 12ms/step\n",
            "Epoch 1/10\n",
            "5/5 [==============================] - 1s 5ms/step - loss: 0.7366 - accuracy: 0.3510\n",
            "Epoch 2/10\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6875 - accuracy: 0.5563\n",
            "Epoch 3/10\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6722 - accuracy: 0.5828\n",
            "Epoch 4/10\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6468 - accuracy: 0.6689\n",
            "Epoch 5/10\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6258 - accuracy: 0.6954\n",
            "Epoch 6/10\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6260 - accuracy: 0.7086\n",
            "Epoch 7/10\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6104 - accuracy: 0.7020\n",
            "Epoch 8/10\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5957 - accuracy: 0.7086\n",
            "Epoch 9/10\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5761 - accuracy: 0.7086\n",
            "Epoch 10/10\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6049 - accuracy: 0.7086\n",
            "5/5 [==============================] - 0s 3ms/step\n",
            "Stacking with CNN Meta-Model - Accuracy: 0.7814569536423841\n"
          ]
        }
      ]
    }
  ]
}